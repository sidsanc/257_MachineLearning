{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidsanc/257_MachineLearning/blob/main/Assignment_5/CMPE_257_Regression%2C_MLP_and_Latent_Manifolds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# House Price Prediction"
      ],
      "metadata": {
        "id": "kNfl_UPUo8TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Dataset"
      ],
      "metadata": {
        "id": "vQ1YCqGc6wa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "PXvmcXoFpNrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_BFP0Sgcs77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "936ce7ae-3f7e-49ff-88ce-a16f8c71f10e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RegionID  SizeRank        RegionName RegionType StateName  2000-01-31  \\\n",
              "0    102001         0     United States    country       NaN    127845.0   \n",
              "1    394913         1      New York, NY        msa        NY    222885.0   \n",
              "2    753899         2   Los Angeles, CA        msa        CA    230273.0   \n",
              "3    394463         3       Chicago, IL        msa        IL    167528.0   \n",
              "4    394514         4        Dallas, TX        msa        TX    128766.0   \n",
              "5    394692         5       Houston, TX        msa        TX    125560.0   \n",
              "6    395209         6    Washington, DC        msa        VA    190329.0   \n",
              "7    394856         7         Miami, FL        msa        FL    123584.0   \n",
              "8    394974         8  Philadelphia, PA        msa        PA    129133.0   \n",
              "9    394347         9       Atlanta, GA        msa        GA    153363.0   \n",
              "\n",
              "   2000-02-29  2000-03-31  2000-04-30  2000-05-31  ...  2022-03-31  \\\n",
              "0    128190.0    128554.0    129295.0    130042.0  ...    337752.0   \n",
              "1    224217.0    225415.0    227774.0    229970.0  ...    587159.0   \n",
              "2    231075.0    232303.0    234638.0    237142.0  ...    904811.0   \n",
              "3    167923.0    168434.0    169458.0    170543.0  ...    295653.0   \n",
              "4    128869.0    128955.0    129164.0    129383.0  ...    363776.0   \n",
              "5    125638.0    125520.0    125638.0    125645.0  ...    292215.0   \n",
              "6    190571.0    190945.0    191739.0    192842.0  ...    536109.0   \n",
              "7    124039.0    124446.0    125248.0    125908.0  ...    413495.0   \n",
              "8    129566.0    129826.0    130472.0    130995.0  ...    321019.0   \n",
              "9    153873.0    154398.0    155461.0    156499.0  ...    359019.0   \n",
              "\n",
              "   2022-04-30  2022-05-31  2022-06-30  2022-07-31  2022-08-31  2022-09-30  \\\n",
              "0    343294.0    348315.0    352484.0    354884.0    355924.0    356279.0   \n",
              "1    594234.0    601691.0    607653.0    611940.0    614208.0    615185.0   \n",
              "2    923996.0    940540.0    941881.0    938738.0    924623.0    914991.0   \n",
              "3    299069.0    302975.0    305916.0    307737.0    308055.0    308352.0   \n",
              "4    373139.0    381724.0    389176.0    391350.0    390417.0    388728.0   \n",
              "5    298181.0    303726.0    307889.0    310472.0    311708.0    312069.0   \n",
              "6    541462.0    545805.0    548084.0    548723.0    547685.0    547681.0   \n",
              "7    424022.0    437311.0    448908.0    459445.0    465946.0    469861.0   \n",
              "8    324676.0    328973.0    332438.0    335051.0    336121.0    337277.0   \n",
              "9    366420.0    373624.0    378969.0    381518.0    382512.0    382347.0   \n",
              "\n",
              "   2022-10-31  2022-11-30  2022-12-31  \n",
              "0    356785.0    357296.0    357319.0  \n",
              "1    615662.0    616681.0    617849.0  \n",
              "2    905397.0    900776.0    897894.0  \n",
              "3    308969.0    309456.0    308959.0  \n",
              "4    388858.0    388704.0    386853.0  \n",
              "5    312657.0    313283.0    312952.0  \n",
              "6    548808.0    550460.0    551220.0  \n",
              "7    471305.0    474405.0    475854.0  \n",
              "8    338871.0    341120.0    343096.0  \n",
              "9    381795.0    381786.0    381245.0  \n",
              "\n",
              "[10 rows x 281 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48159e24-d1f7-4f35-8524-b3eb2ce60c2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RegionID</th>\n",
              "      <th>SizeRank</th>\n",
              "      <th>RegionName</th>\n",
              "      <th>RegionType</th>\n",
              "      <th>StateName</th>\n",
              "      <th>2000-01-31</th>\n",
              "      <th>2000-02-29</th>\n",
              "      <th>2000-03-31</th>\n",
              "      <th>2000-04-30</th>\n",
              "      <th>2000-05-31</th>\n",
              "      <th>...</th>\n",
              "      <th>2022-03-31</th>\n",
              "      <th>2022-04-30</th>\n",
              "      <th>2022-05-31</th>\n",
              "      <th>2022-06-30</th>\n",
              "      <th>2022-07-31</th>\n",
              "      <th>2022-08-31</th>\n",
              "      <th>2022-09-30</th>\n",
              "      <th>2022-10-31</th>\n",
              "      <th>2022-11-30</th>\n",
              "      <th>2022-12-31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102001</td>\n",
              "      <td>0</td>\n",
              "      <td>United States</td>\n",
              "      <td>country</td>\n",
              "      <td>NaN</td>\n",
              "      <td>127845.0</td>\n",
              "      <td>128190.0</td>\n",
              "      <td>128554.0</td>\n",
              "      <td>129295.0</td>\n",
              "      <td>130042.0</td>\n",
              "      <td>...</td>\n",
              "      <td>337752.0</td>\n",
              "      <td>343294.0</td>\n",
              "      <td>348315.0</td>\n",
              "      <td>352484.0</td>\n",
              "      <td>354884.0</td>\n",
              "      <td>355924.0</td>\n",
              "      <td>356279.0</td>\n",
              "      <td>356785.0</td>\n",
              "      <td>357296.0</td>\n",
              "      <td>357319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>394913</td>\n",
              "      <td>1</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>msa</td>\n",
              "      <td>NY</td>\n",
              "      <td>222885.0</td>\n",
              "      <td>224217.0</td>\n",
              "      <td>225415.0</td>\n",
              "      <td>227774.0</td>\n",
              "      <td>229970.0</td>\n",
              "      <td>...</td>\n",
              "      <td>587159.0</td>\n",
              "      <td>594234.0</td>\n",
              "      <td>601691.0</td>\n",
              "      <td>607653.0</td>\n",
              "      <td>611940.0</td>\n",
              "      <td>614208.0</td>\n",
              "      <td>615185.0</td>\n",
              "      <td>615662.0</td>\n",
              "      <td>616681.0</td>\n",
              "      <td>617849.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>753899</td>\n",
              "      <td>2</td>\n",
              "      <td>Los Angeles, CA</td>\n",
              "      <td>msa</td>\n",
              "      <td>CA</td>\n",
              "      <td>230273.0</td>\n",
              "      <td>231075.0</td>\n",
              "      <td>232303.0</td>\n",
              "      <td>234638.0</td>\n",
              "      <td>237142.0</td>\n",
              "      <td>...</td>\n",
              "      <td>904811.0</td>\n",
              "      <td>923996.0</td>\n",
              "      <td>940540.0</td>\n",
              "      <td>941881.0</td>\n",
              "      <td>938738.0</td>\n",
              "      <td>924623.0</td>\n",
              "      <td>914991.0</td>\n",
              "      <td>905397.0</td>\n",
              "      <td>900776.0</td>\n",
              "      <td>897894.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>394463</td>\n",
              "      <td>3</td>\n",
              "      <td>Chicago, IL</td>\n",
              "      <td>msa</td>\n",
              "      <td>IL</td>\n",
              "      <td>167528.0</td>\n",
              "      <td>167923.0</td>\n",
              "      <td>168434.0</td>\n",
              "      <td>169458.0</td>\n",
              "      <td>170543.0</td>\n",
              "      <td>...</td>\n",
              "      <td>295653.0</td>\n",
              "      <td>299069.0</td>\n",
              "      <td>302975.0</td>\n",
              "      <td>305916.0</td>\n",
              "      <td>307737.0</td>\n",
              "      <td>308055.0</td>\n",
              "      <td>308352.0</td>\n",
              "      <td>308969.0</td>\n",
              "      <td>309456.0</td>\n",
              "      <td>308959.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>394514</td>\n",
              "      <td>4</td>\n",
              "      <td>Dallas, TX</td>\n",
              "      <td>msa</td>\n",
              "      <td>TX</td>\n",
              "      <td>128766.0</td>\n",
              "      <td>128869.0</td>\n",
              "      <td>128955.0</td>\n",
              "      <td>129164.0</td>\n",
              "      <td>129383.0</td>\n",
              "      <td>...</td>\n",
              "      <td>363776.0</td>\n",
              "      <td>373139.0</td>\n",
              "      <td>381724.0</td>\n",
              "      <td>389176.0</td>\n",
              "      <td>391350.0</td>\n",
              "      <td>390417.0</td>\n",
              "      <td>388728.0</td>\n",
              "      <td>388858.0</td>\n",
              "      <td>388704.0</td>\n",
              "      <td>386853.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>394692</td>\n",
              "      <td>5</td>\n",
              "      <td>Houston, TX</td>\n",
              "      <td>msa</td>\n",
              "      <td>TX</td>\n",
              "      <td>125560.0</td>\n",
              "      <td>125638.0</td>\n",
              "      <td>125520.0</td>\n",
              "      <td>125638.0</td>\n",
              "      <td>125645.0</td>\n",
              "      <td>...</td>\n",
              "      <td>292215.0</td>\n",
              "      <td>298181.0</td>\n",
              "      <td>303726.0</td>\n",
              "      <td>307889.0</td>\n",
              "      <td>310472.0</td>\n",
              "      <td>311708.0</td>\n",
              "      <td>312069.0</td>\n",
              "      <td>312657.0</td>\n",
              "      <td>313283.0</td>\n",
              "      <td>312952.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>395209</td>\n",
              "      <td>6</td>\n",
              "      <td>Washington, DC</td>\n",
              "      <td>msa</td>\n",
              "      <td>VA</td>\n",
              "      <td>190329.0</td>\n",
              "      <td>190571.0</td>\n",
              "      <td>190945.0</td>\n",
              "      <td>191739.0</td>\n",
              "      <td>192842.0</td>\n",
              "      <td>...</td>\n",
              "      <td>536109.0</td>\n",
              "      <td>541462.0</td>\n",
              "      <td>545805.0</td>\n",
              "      <td>548084.0</td>\n",
              "      <td>548723.0</td>\n",
              "      <td>547685.0</td>\n",
              "      <td>547681.0</td>\n",
              "      <td>548808.0</td>\n",
              "      <td>550460.0</td>\n",
              "      <td>551220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>394856</td>\n",
              "      <td>7</td>\n",
              "      <td>Miami, FL</td>\n",
              "      <td>msa</td>\n",
              "      <td>FL</td>\n",
              "      <td>123584.0</td>\n",
              "      <td>124039.0</td>\n",
              "      <td>124446.0</td>\n",
              "      <td>125248.0</td>\n",
              "      <td>125908.0</td>\n",
              "      <td>...</td>\n",
              "      <td>413495.0</td>\n",
              "      <td>424022.0</td>\n",
              "      <td>437311.0</td>\n",
              "      <td>448908.0</td>\n",
              "      <td>459445.0</td>\n",
              "      <td>465946.0</td>\n",
              "      <td>469861.0</td>\n",
              "      <td>471305.0</td>\n",
              "      <td>474405.0</td>\n",
              "      <td>475854.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>394974</td>\n",
              "      <td>8</td>\n",
              "      <td>Philadelphia, PA</td>\n",
              "      <td>msa</td>\n",
              "      <td>PA</td>\n",
              "      <td>129133.0</td>\n",
              "      <td>129566.0</td>\n",
              "      <td>129826.0</td>\n",
              "      <td>130472.0</td>\n",
              "      <td>130995.0</td>\n",
              "      <td>...</td>\n",
              "      <td>321019.0</td>\n",
              "      <td>324676.0</td>\n",
              "      <td>328973.0</td>\n",
              "      <td>332438.0</td>\n",
              "      <td>335051.0</td>\n",
              "      <td>336121.0</td>\n",
              "      <td>337277.0</td>\n",
              "      <td>338871.0</td>\n",
              "      <td>341120.0</td>\n",
              "      <td>343096.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>394347</td>\n",
              "      <td>9</td>\n",
              "      <td>Atlanta, GA</td>\n",
              "      <td>msa</td>\n",
              "      <td>GA</td>\n",
              "      <td>153363.0</td>\n",
              "      <td>153873.0</td>\n",
              "      <td>154398.0</td>\n",
              "      <td>155461.0</td>\n",
              "      <td>156499.0</td>\n",
              "      <td>...</td>\n",
              "      <td>359019.0</td>\n",
              "      <td>366420.0</td>\n",
              "      <td>373624.0</td>\n",
              "      <td>378969.0</td>\n",
              "      <td>381518.0</td>\n",
              "      <td>382512.0</td>\n",
              "      <td>382347.0</td>\n",
              "      <td>381795.0</td>\n",
              "      <td>381786.0</td>\n",
              "      <td>381245.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 281 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48159e24-d1f7-4f35-8524-b3eb2ce60c2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48159e24-d1f7-4f35-8524-b3eb2ce60c2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48159e24-d1f7-4f35-8524-b3eb2ce60c2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "url1 = 'https://drive.google.com/file/d/1p4BNeW3kp7-Ruiukio3q25O_SA2pICCY/view'\n",
        "url1 ='https://drive.google.com/uc?id=' + url1.split('/')[-2]\n",
        "data1 = pd.read_csv(url1)\n",
        "data1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1['RegionName'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-quSmbO0IG3",
        "outputId": "39faf268-e4af-4d55-ab60-421ec3380960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['United States', 'New York, NY', 'Los Angeles, CA', 'Chicago, IL',\n",
              "       'Dallas, TX', 'Houston, TX', 'Washington, DC', 'Miami, FL',\n",
              "       'Philadelphia, PA', 'Atlanta, GA', 'Phoenix, AZ', 'Boston, MA',\n",
              "       'San Francisco, CA', 'Riverside, CA', 'Detroit, MI', 'Seattle, WA',\n",
              "       'Minneapolis, MN', 'San Diego, CA', 'Tampa, FL', 'Denver, CO',\n",
              "       'St. Louis, MO', 'Baltimore, MD', 'Charlotte, NC', 'Orlando, FL',\n",
              "       'San Antonio, TX', 'Portland, OR', 'Sacramento, CA',\n",
              "       'Las Vegas, NV', 'Pittsburgh, PA', 'Austin, TX', 'Cincinnati, OH',\n",
              "       'Kansas City, MO', 'Columbus, OH', 'Indianapolis, IN',\n",
              "       'Cleveland, OH', 'San Jose, CA', 'Nashville, TN',\n",
              "       'Virginia Beach, VA', 'Providence, RI', 'Jacksonville, FL',\n",
              "       'Milwaukee, WI', 'Oklahoma City, OK', 'Raleigh, NC', 'Memphis, TN',\n",
              "       'Richmond, VA', 'New Orleans, LA', 'Louisville, KY',\n",
              "       'Salt Lake City, UT', 'Hartford, CT', 'Buffalo, NY',\n",
              "       'Birmingham, AL', 'Grand Rapids, MI', 'Rochester, NY',\n",
              "       'Tucson, AZ', 'Tulsa, OK', 'Fresno, CA', 'Urban Honolulu, HI',\n",
              "       'Omaha, NE', 'Worcester, MA', 'Bridgeport, CT', 'Greenville, SC',\n",
              "       'Albuquerque, NM', 'Bakersfield, CA', 'Albany, NY',\n",
              "       'Knoxville, TN', 'McAllen, TX', 'Baton Rouge, LA',\n",
              "       'North Port, FL', 'New Haven, CT', 'Columbia, SC', 'Allentown, PA',\n",
              "       'El Paso, TX', 'Oxnard, CA', 'Charleston, SC', 'Dayton, OH',\n",
              "       'Cape Coral, FL', 'Greensboro, NC', 'Boise City, ID',\n",
              "       'Stockton, CA', 'Colorado Springs, CO', 'Little Rock, AR',\n",
              "       'Lakeland, FL', 'Des Moines, IA', 'Akron, OH', 'Springfield, MA',\n",
              "       'Ogden, UT', 'Deltona, FL', 'Winston, NC', 'Madison, WI',\n",
              "       'Provo, UT', 'Durham, NC', 'Syracuse, NY', 'Wichita, KS',\n",
              "       'Toledo, OH', 'Augusta, GA', 'Palm Bay, FL', 'Jackson, MS',\n",
              "       'Harrisburg, PA', 'Spokane, WA', 'Chattanooga, TN', 'Scranton, PA',\n",
              "       'Modesto, CA', 'Fayetteville, AR', 'Lansing, MI', 'Lancaster, PA',\n",
              "       'Portland, ME', 'Youngstown, OH', 'Fayetteville, NC',\n",
              "       'Lexington, KY', 'Myrtle Beach, SC', 'Pensacola, FL',\n",
              "       'Port St. Lucie, FL', 'Santa Rosa, CA', 'Lafayette, LA',\n",
              "       'Huntsville, AL', 'Reno, NV', 'Springfield, MO', 'Visalia, CA',\n",
              "       'Killeen, TX', 'Asheville, NC', 'York, PA', 'Vallejo, CA',\n",
              "       'Santa Maria, CA', 'Salem, OR', 'Salinas, CA',\n",
              "       'Corpus Christi, TX', 'Mobile, AL', 'Brownsville, TX',\n",
              "       'Salisbury, MD', 'Reading, PA', 'Gulfport, MS', 'Manchester, NH',\n",
              "       'Fort Wayne, IN', 'Flint, MI', 'Anchorage, AK', 'Peoria, IL',\n",
              "       'Canton, OH', 'Savannah, GA', 'Naples, FL', 'Shreveport, LA',\n",
              "       'Beaumont, TX', 'Tallahassee, FL', 'Eugene, OR', 'Davenport, IA',\n",
              "       'Ocala, FL', 'Montgomery, AL', 'Hickory, NC', 'Trenton, NJ',\n",
              "       'Ann Arbor, MI', 'Fort Collins, CO', 'Huntington, WV',\n",
              "       'Lincoln, NE', 'Rockford, IL', 'Greeley, CO', 'Gainesville, FL',\n",
              "       'Boulder, CO', 'Lubbock, TX', 'Spartanburg, SC', 'Green Bay, WI',\n",
              "       'South Bend, IN', 'Columbus, GA', 'Evansville, IN',\n",
              "       'Clarksville, TN', 'Roanoke, VA', 'Kingsport, TN', 'Kennewick, WA',\n",
              "       'Wilmington, NC', 'Olympia, WA', 'Hagerstown, MD', 'Crestview, FL',\n",
              "       'Duluth, MN', 'Utica, NY', 'Longview, TX', 'San Luis Obispo, CA',\n",
              "       'Merced, CA', 'Laredo, TX', 'Waco, TX', 'Cedar Rapids, IA',\n",
              "       'Sioux Falls, SD', 'Bremerton, WA', 'Santa Cruz, CA', 'Erie, PA',\n",
              "       'College Station, TX', 'Kalamazoo, MI', 'Amarillo, TX',\n",
              "       'Norwich, CT', 'Lynchburg, VA', 'Atlantic City, NJ',\n",
              "       'Charleston, WV', 'Tuscaloosa, AL', 'Yakima, WA', 'Fort Smith, AR',\n",
              "       'Fargo, ND', 'Prescott Valley, AZ', 'Appleton, WI',\n",
              "       'Binghamton, NY', 'Tyler, TX', 'Lafayette, IN', 'Bellingham, WA',\n",
              "       'Topeka, KS', 'Macon, GA', 'Daphne, AL', 'Hilton Head Island, SC',\n",
              "       'Champaign, IL', 'Rochester, MN', 'Medford, OR', 'Las Cruces, NM',\n",
              "       'Burlington, VT', 'Charlottesville, VA', 'Yuma, AZ', 'Lebanon, NH',\n",
              "       'Lake Havasu City, AZ', 'Athens, GA', 'Barnstable Town, MA',\n",
              "       'Chico, CA', 'Lake Charles, LA', 'Columbia, MO', 'Houma, LA',\n",
              "       'Gainesville, GA', 'Elkhart, IN', 'Springfield, IL',\n",
              "       'Johnson City, TN', 'Florence, SC', 'Jacksonville, NC', 'Hilo, HI',\n",
              "       'St. Cloud, MN', 'Bend, OR', 'Monroe, LA', 'Racine, WI',\n",
              "       'Punta Gorda, FL', 'Saginaw, MI', 'Warner Robins, GA',\n",
              "       'Terre Haute, IN', 'St. George, UT', 'Billings, MT', 'Midland, TX',\n",
              "       'Dover, DE', 'Greenville, NC', 'Bowling Green, KY',\n",
              "       'El Centro, CA', 'Joplin, MO', 'Torrington, CT', 'Jackson, TN',\n",
              "       'Redding, CA', 'Kingston, NY', 'Yuba City, CA', 'Iowa City, IA',\n",
              "       'Muskegon, MI', 'Abilene, TX', 'Oshkosh, WI', 'Burlington, NC',\n",
              "       'Panama City, FL', 'Bloomington, IL', \"Coeur d'Alene, ID\",\n",
              "       'East Stroudsburg, PA', 'Eau Claire, WI', 'Pueblo, CO',\n",
              "       'Hattiesburg, MS', 'Bloomington, IN', 'Waterloo, IA',\n",
              "       'Kahului, HI', 'Odessa, TX', 'Blacksburg, VA', 'Auburn, AL',\n",
              "       'Tupelo, MS', 'Wausau, WI', 'Janesville, WI', 'Sebastian, FL',\n",
              "       'State College, PA', 'Madera, CA', 'Jackson, MI',\n",
              "       'Chambersburg, PA', 'Grand Junction, CO', 'Idaho Falls, ID',\n",
              "       'Elizabethtown, KY', 'Niles, MI', 'Homosassa Springs, FL',\n",
              "       'Decatur, AL', 'Hanford, CA', 'Concord, NH', 'Wichita Falls, TX',\n",
              "       'Santa Fe, NM', 'Bangor, ME', 'Traverse City, MI',\n",
              "       'Alexandria, LA', 'Monroe, MI', 'Dothan, AL', 'Jefferson City, MO',\n",
              "       'Texarkana, TX', 'Florence, AL', 'Valdosta, GA', 'London, KY',\n",
              "       'Vineland, NJ', 'Rocky Mount, NC', 'Ottawa, IL', 'Albany, GA',\n",
              "       'Sioux City, IA', 'Rapid City, SD', 'Logan, UT', 'Morristown, TN',\n",
              "       'Dalton, GA', 'Flagstaff, AZ', 'Winchester, VA', 'Lebanon, PA',\n",
              "       'Pottsville, PA', 'Morgantown, WV', 'Sumter, SC',\n",
              "       'The Villages, FL', 'Sherman, TX', 'Wheeling, WV', 'La Crosse, WI',\n",
              "       'Hammond, LA', 'Napa, CA', 'Harrisonburg, VA', 'Jonesboro, AR',\n",
              "       'Carbondale, IL', 'Eureka, CA', 'Springfield, OH',\n",
              "       'Battle Creek, MI', 'Albany, OR', 'Mount Vernon, WA',\n",
              "       'Manhattan, KS', 'Lumberton, NC', 'Bismarck, ND', 'Johnstown, PA',\n",
              "       'Sierra Vista, AZ', 'Lawton, OK', 'Jamestown, NY', 'Cleveland, TN',\n",
              "       'Pittsfield, MA', 'Ames, IA', 'Staunton, VA', 'Glens Falls, NY',\n",
              "       'Goldsboro, NC', 'Farmington, NM', 'New Bern, NC', 'Augusta, ME',\n",
              "       'San Angelo, TX', 'St. Joseph, MO', 'Lawrence, KS', 'Missoula, MT',\n",
              "       'Wenatchee, WA', 'Altoona, PA', 'Mansfield, OH', 'Owensboro, KY',\n",
              "       'Brunswick, GA', 'Holland, MI', 'Bozeman, MT', 'Wooster, OH',\n",
              "       'Cookeville, TN', 'Sheboygan, WI', 'Weirton, WV', 'Beckley, WV',\n",
              "       'California, MD', 'Anniston, AL', 'Muncie, IN', 'Williamsport, PA',\n",
              "       'Twin Falls, ID', 'Show Low, AZ', 'Longview, WA', 'Roseburg, OR',\n",
              "       'Michigan City, IN', 'Kankakee, IL', 'Lewiston, ME',\n",
              "       'Richmond, KY', 'Watertown, NY', 'Ogdensburg, NY', 'Sebring, FL',\n",
              "       'Tullahoma, TN', 'Kalispell, MT', 'Bluefield, WV',\n",
              "       'Whitewater, WI', 'Pinehurst, NC', 'LaGrange, GA', 'Decatur, IL',\n",
              "       'Fond du Lac, WI', 'Gettysburg, PA', 'Mankato, MN', 'Bay City, MI',\n",
              "       'Gadsden, AL', 'Lima, OH', 'Salem, OH', 'Ithaca, NY',\n",
              "       'Cheyenne, WY', 'Grand Forks, ND', 'Hot Springs, AR',\n",
              "       'Danville, VA', 'Truckee, CA', 'Victoria, TX', 'Moses Lake, WA',\n",
              "       'Sevierville, TN', 'Shelby, NC', 'Rome, GA', 'Meridian, MS',\n",
              "       'Adrian, MI', 'Dubuque, IA', 'Cape Girardeau, MO',\n",
              "       'Albertville, AL', 'Cumberland, MD', 'Ashtabula, OH',\n",
              "       'Pocatello, ID', 'Paducah, KY', 'Fairbanks, AK', 'Brainerd, MN',\n",
              "       'Corning, NY', 'Corvallis, OR', 'Clarksburg, WV',\n",
              "       'New Philadelphia, OH', 'Ocean City, NJ', 'Sunbury, PA',\n",
              "       'Hermiston, OR', 'Parkersburg, WV', 'Grants Pass, OR',\n",
              "       'Beaver Dam, WI', 'Lufkin, TX', 'Pine Bluff, AR', 'Ukiah, CA',\n",
              "       'Zanesville, OH', 'Oak Harbor, WA', 'Russellville, AR',\n",
              "       'Orangeburg, SC', 'New Castle, PA', 'Watertown, WI', 'Cullman, AL',\n",
              "       'Columbus, IN', 'Laurel, MS', 'Athens, TX', 'Meadville, PA',\n",
              "       'Indiana, PA', 'Midland, MI', 'Hinesville, GA', 'Bloomsburg, PA',\n",
              "       'Kokomo, IN', 'Elmira, NY', 'Helena, MT', 'Centralia, WA',\n",
              "       'Wilson, NC', 'Stillwater, OK', 'Opelousas, LA', 'Great Falls, MT',\n",
              "       'Statesboro, GA', 'Casper, WY', 'Seneca, SC', 'Talladega, AL',\n",
              "       'Plattsburgh, NY', 'Warsaw, IN', 'Manitowoc, WI', 'Searcy, AR',\n",
              "       'DuBois, PA', 'Glenwood Springs, CO', 'Port Angeles, WA',\n",
              "       'Heber, UT', 'Minot, ND', 'Chillicothe, OH', 'Keene, NH',\n",
              "       'Jefferson, GA', 'Auburn, NY', 'Aberdeen, WA', 'Olean, NY',\n",
              "       'Findlay, OH', 'Grand Island, NE', 'Danville, IL', 'Palatka, FL',\n",
              "       'Quincy, IL', 'Portsmouth, OH', 'Frankfort, KY', 'Key West, FL',\n",
              "       'Sandusky, OH', 'Shawnee, OK', 'Somerset, PA', 'Lake City, FL',\n",
              "       'Wisconsin Rapids, WI', 'Huntsville, TX', 'Kapaa, HI', 'Hobbs, NM',\n",
              "       'Mount Airy, NC', 'Greenwood, SC', 'Stevens Point, WI',\n",
              "       'Gallup, NM', 'Greeneville, TN', 'Morehead City, NC',\n",
              "       'Mount Pleasant, MI', 'Klamath Falls, OR', 'Roanoke Rapids, NC',\n",
              "       'Shelton, WA', 'North Wilkesboro, NC', 'Alamogordo, NM',\n",
              "       'Muskogee, OK', 'Faribault, MN', 'Forest City, NC',\n",
              "       'Farmington, MO', 'Marquette, MI', 'Richmond, IN', 'Somerset, KY',\n",
              "       'Athens, OH', 'Marion, IN', 'Marion, OH', 'Nacogdoches, TX',\n",
              "       'Roswell, NM', 'Coos Bay, OR', 'Red Bluff, CA', 'Clearlake, CA',\n",
              "       'Baraboo, WI', 'Rio Grande City, TX', 'Dublin, GA', 'Lewiston, ID',\n",
              "       'Georgetown, SC', 'Marinette, WI', 'Martinsville, VA',\n",
              "       'Mount Vernon, OH', 'Sanford, NC', 'Hutchinson, KS',\n",
              "       'Crossville, TN', 'Laconia, NH', 'Walla Walla, WA',\n",
              "       'Charleston, IL', 'Gillette, WY', 'Enid, OK', 'Sturgis, MI',\n",
              "       'Sayre, PA', 'Marietta, OH', 'Salina, KS', 'Hudson, NY',\n",
              "       'Starkville, MS', 'Calhoun, GA', 'Fergus Falls, MN', 'Oneonta, NY',\n",
              "       'Ardmore, OK', 'Eagle Pass, TX', 'Fremont, OH', 'Barre, VT',\n",
              "       'Fernley, NV', 'Columbus, MS', 'Cullowhee, NC', 'Norwalk, OH',\n",
              "       'Palestine, TX', 'Rutland, VT', 'Fort Madison, IA', 'Gaffney, SC',\n",
              "       'Batavia, NY', 'Cedar City, UT', 'Kearney, NE', 'Durango, CO',\n",
              "       'Boone, NC', 'Point Pleasant, WV', 'Branson, MO',\n",
              "       'Carson City, NV', 'Fairmont, WV', 'Picayune, MS', 'Ontario, OR',\n",
              "       'Kinston, NC', 'Poplar Bluff, MO', 'St. Marys, GA', 'Waycross, GA',\n",
              "       'Batesville, AR', 'Elko, NV', 'Tiffin, OH', 'Edwards, CO',\n",
              "       'Jasper, IN', 'Danville, KY', 'Sterling, IL', 'Sonora, CA',\n",
              "       'Oxford, MS', 'Glasgow, KY', 'Payson, AZ', 'Warrensburg, MO',\n",
              "       'Athens, TN', 'Elizabeth City, NC', 'Milledgeville, GA',\n",
              "       'Rexburg, ID', 'Ashland, OH', 'Enterprise, AL', 'Jacksonville, TX',\n",
              "       'Kerrville, TX', 'Gloversville, NY', 'Fort Leonard Wood, MO',\n",
              "       'Bartlesville, OK', 'Douglas, GA', 'Scottsboro, AL', 'Alice, TX',\n",
              "       'Greenville, OH', 'Platteville, WI', 'Corsicana, TX',\n",
              "       'Newport, OR', 'Winona, MN', 'Oil City, PA', 'Rochelle, IL',\n",
              "       'Shelbyville, TN', 'Malone, NY', 'Paris, TX', 'Pullman, WA',\n",
              "       'Mason City, IA', 'Ellensburg, WA', 'Natchez, MS', 'Amsterdam, NY',\n",
              "       'Gardnerville Ranchos, NV', 'Galesburg, IL', 'Del Rio, TX',\n",
              "       'Tahlequah, OK', 'Durant, OK', 'Ozark, AL', 'Cadillac, MI',\n",
              "       'Clovis, NM', 'Sidney, OH', 'Morgan City, LA', 'Montrose, CO',\n",
              "       'Pahrump, NV', 'New Castle, IN', 'Fort Polk South, LA',\n",
              "       'Norfolk, NE', 'Ca-¦on City, CO', 'Kendallville, IN',\n",
              "       'Bemidji, MN', 'Blackfoot, ID', 'Cortland, NY',\n",
              "       'Mount Sterling, KY', 'Washington, NC', 'Sandpoint, ID',\n",
              "       'Nogales, AZ', 'Ruston, LA', 'Bardstown, KY', 'Clinton, IA',\n",
              "       'Red Wing, MN', 'Plymouth, IN', 'Lewistown, PA', 'Cornelia, GA',\n",
              "       'Mount Pleasant, TX', 'Marion, NC', 'Bogalusa, LA',\n",
              "       'Wapakoneta, OH', 'Hillsdale, MI', 'Paragould, AR', 'Moultrie, GA',\n",
              "       'Bedford, IN', 'Burley, ID', 'Menomonie, WI', 'Shawano, WI',\n",
              "       'Bellefontaine, OH', 'Burlington, IA', 'Harrison, AR',\n",
              "       'Vicksburg, MS', 'Henderson, NC', 'Madisonville, KY',\n",
              "       'Huntingdon, PA', 'Lawrenceburg, TN', 'Rolla, MO',\n",
              "       'Thomasville, GA', 'Rockingham, NC', 'Lewisburg, PA',\n",
              "       'Seymour, IN', 'Big Rapids, MI', 'Freeport, IL', 'McAlester, OK',\n",
              "       'Auburn, IN', 'Coldwater, MI', 'Ponca City, OK',\n",
              "       'Stephenville, TX', 'Willmar, MN', 'Duncan, OK', 'Cedartown, GA',\n",
              "       'Clewiston, FL', 'Rock Springs, WY', 'Aberdeen, SD', 'Sedalia, MO',\n",
              "       'Muscatine, IA', 'Okeechobee, FL', 'Mountain Home, AR',\n",
              "       'Wilmington, OH', 'El Campo, TX', 'McMinnville, TN',\n",
              "       'Gainesville, TX', 'Bucyrus, OH', 'Celina, OH',\n",
              "       'Big Stone Gap, VA', 'Moscow, ID', 'Tifton, GA', 'Astoria, OR',\n",
              "       'Bradford, PA', 'Selinsgrove, PA', 'Alma, MI', 'West Plains, MO',\n",
              "       'Austin, MN', 'Blytheville, AR', 'Garden City, KS',\n",
              "       'Marshalltown, IA', 'Riverton, WY', 'Murray, KY', 'Safford, AZ',\n",
              "       'McComb, MS', 'Urbana, OH', 'Laramie, WY', 'Warren, PA',\n",
              "       'Cambridge, OH', 'Pittsburg, KS', 'Hannibal, MO', 'Williston, ND',\n",
              "       'Espa-¦ola, NM', 'Arcadia, FL', 'Newberry, SC', 'Ada, OK',\n",
              "       'Crawfordsville, IN', 'Jacksonville, IL', 'Alexandria, MN',\n",
              "       'Sikeston, MO', 'El Dorado, AR', 'Lock Haven, PA', 'DeRidder, LA',\n",
              "       'Defiance, OH', 'Natchitoches, LA', 'Brownwood, TX',\n",
              "       'Greenwood, MS', 'Kill Devil Hills, NC', 'Logansport, IN',\n",
              "       'Scottsbluff, NE', 'Houghton, MI', 'Mount Vernon, IL',\n",
              "       'Sulphur Springs, TX', 'Easton, MD', 'Sault Ste. Marie, MI',\n",
              "       'Corinth, MS', 'Mayfield, KY', 'Bay City, TX',\n",
              "       'Campbellsville, KY', 'Dyersburg, TN', 'Owatonna, MN',\n",
              "       'Big Spring, TX', 'Vincennes, IN', 'Coshocton, OH',\n",
              "       'Huntington, IN', 'Newport, TN', 'Fremont, NE', 'Selma, AL',\n",
              "       'Jackson, WY', 'Vidalia, GA', 'Vernal, UT', 'Lebanon, MO',\n",
              "       'Decatur, IN', 'Brenham, TX', 'Hutchinson, MN', 'Emporia, KS',\n",
              "       'Escanaba, MI', 'Brookings, SD', 'North Platte, NE', 'Pontiac, IL',\n",
              "       'Bennington, VT', 'Peru, IN', 'Butte, MT', 'Lewisburg, TN',\n",
              "       'Ottumwa, IA', 'Angola, IN', 'Laurinburg, NC', 'Winfield, KS',\n",
              "       'Brevard, NC', 'Americus, GA', 'Watertown, SD', 'Effingham, IL',\n",
              "       'Seneca Falls, NY', 'Brookhaven, MS', 'Malvern, AR', 'Dixon, IL',\n",
              "       'Washington, IN', 'Dayton, TN', 'Columbus, NE', 'Martin, TN',\n",
              "       'Dodge City, KS', 'Dickinson, ND', 'Troy, AL', 'Plainview, TX',\n",
              "       'Taos, NM', 'Beeville, TX', 'Jackson, OH', 'Frankfort, IN',\n",
              "       'Madison, IN', 'Taylorville, IL', 'Paris, TN', 'Cambridge, MD',\n",
              "       'Juneau, AK', 'Mount Gay, WV', 'Las Vegas, NM', 'Coffeyville, KS',\n",
              "       'Hastings, NE', 'Berlin, NH', 'Miami, OK', 'Sheridan, WY',\n",
              "       'Wabash, IN', 'Kingsville, TX', 'Breckenridge, CO',\n",
              "       'Albert Lea, MN', 'Union City, TN', 'Jesup, GA', 'Susanville, CA',\n",
              "       'Kirksville, MO', 'Iron Mountain, MI', 'Mineral Wells, TX',\n",
              "       'Macomb, IL', 'Ludington, MI', 'Fort Morgan, CO', 'Kennett, MO',\n",
              "       'Hays, KS', 'Weatherford, OK', 'Washington Court House, OH',\n",
              "       'McPherson, KS', 'Elkins, WV', 'Lincoln, IL', 'Camden, AR',\n",
              "       'Alpena, MI', 'Van Wert, OH', 'Crescent City, CA',\n",
              "       'North Vernon, IN', 'Mountain Home, ID', 'Silver City, NM',\n",
              "       'Fredericksburg, TX', 'Wauchula, FL', 'Uvalde, TX',\n",
              "       'Greensburg, IN', 'La Grande, OR', 'Thomaston, GA',\n",
              "       'Bainbridge, GA', 'The Dalles, OR', 'Spearfish, SD', 'Toccoa, GA',\n",
              "       'Ottawa, KS', 'Great Bend, KS', 'Bennettsville, SC',\n",
              "       'Steamboat Springs, CO', 'Lexington, NE', 'Middlesborough, KY',\n",
              "       'Fallon, NV', 'Marshall, MN', 'Prineville, OR', 'New Ulm, MN',\n",
              "       'Summerville, GA', 'Mexico, MO', 'Indianola, MS',\n",
              "       'Forrest City, AR', 'Hailey, ID', 'Moberly, MO', 'Altus, OK',\n",
              "       'Deming, NM', 'Woodward, OK', 'Magnolia, AR', 'Brookings, OR',\n",
              "       'Mitchell, SD', 'Hood River, OR', 'Levelland, TX',\n",
              "       'Connersville, IN', 'Marshall, MO', 'Yankton, SD', 'Pampa, TX',\n",
              "       'Oskaloosa, IA', 'Wahpeton, ND', 'Arkadelphia, AR', 'Cordele, GA',\n",
              "       'Sterling, CO', 'Maryville, MO', 'Elk City, OK', 'Beatrice, NE',\n",
              "       'Worthington, MN', 'Raymondville, TX', 'Liberal, KS',\n",
              "       'Port Lavaca, TX', 'Borger, TX', 'Dumas, TX', 'Grenada, MS',\n",
              "       'Jamestown, ND', 'Pierre, SD', 'Evanston, WY', 'Othello, WA',\n",
              "       'Guymon, OK', 'Storm Lake, IA', 'Parsons, KS', 'Los Alamos, NM',\n",
              "       'Andrews, TX', 'Portales, NM', 'Fairfield, IA', 'Hereford, TX',\n",
              "       'Spirit Lake, IA', 'Vineyard Haven, MA', 'Helena, AR',\n",
              "       'Maysville, KY', 'Winnemucca, NV', 'Snyder, TX', 'Fitzgerald, GA',\n",
              "       'Pecos, TX', 'Atchison, KS', 'Spencer, IA', 'Sweetwater, TX',\n",
              "       'Vermillion, SD', 'Zapata, TX', 'Ketchikan, AK', 'Craig, CO',\n",
              "       'Lamesa, TX', 'Vernon, TX'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing another dataset for Latent Variables"
      ],
      "metadata": {
        "id": "C-kREP_WSYja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# walkability_url = 'https://drive.google.com/file/d/1yCz6FYet7_dwq4sHQxc67xcujvQbxTuU/view'\n",
        "# walkability_url ='https://drive.google.com/uc?id=' + walkability_url.split('/')[-2]\n",
        "walkability_df = pd.read_csv('/content/EPA_SmartLocationDatabase_V3_Jan_2021_Final.csv')\n",
        "walkability_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "HLl2JZB_zdDq",
        "outputId": "a07e30df-eb76-407e-afcf-5f235c9bafec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   OBJECTID       GEOID10       GEOID20  STATEFP  COUNTYFP  TRACTCE  BLKGRPCE  \\\n",
              "0         1  4.811300e+11  4.811300e+11       48       113     7825         4   \n",
              "1         2  4.811300e+11  4.811300e+11       48       113     7825         2   \n",
              "2         3  4.811300e+11  4.811300e+11       48       113     7825         3   \n",
              "3         4  4.811300e+11  4.811300e+11       48       113     7824         1   \n",
              "4         5  4.811300e+11  4.811300e+11       48       113     7824         2   \n",
              "\n",
              "     CSA                  CSA_Name     CBSA  ...     D5DRI      D5DE  \\\n",
              "0  206.0  Dallas-Fort Worth, TX-OK  19100.0  ...  0.184697  0.000476   \n",
              "1  206.0  Dallas-Fort Worth, TX-OK  19100.0  ...  0.323221  0.000801   \n",
              "2  206.0  Dallas-Fort Worth, TX-OK  19100.0  ...  0.314628  0.000736   \n",
              "3  206.0  Dallas-Fort Worth, TX-OK  19100.0  ...  0.229821  0.000708   \n",
              "4  206.0  Dallas-Fort Worth, TX-OK  19100.0  ...  0.164863  0.000433   \n",
              "\n",
              "      D5DEI  D2A_Ranked  D2B_Ranked  D3B_Ranked  D4A_Ranked  NatWalkInd  \\\n",
              "0  0.137707           6          14          15          17   14.000000   \n",
              "1  0.231868           3          10          12          14   10.833333   \n",
              "2  0.213146           1           1           7          17    8.333333   \n",
              "3  0.205018          16          10          17          17   15.666667   \n",
              "4  0.125296           4           7          11          14   10.166667   \n",
              "\n",
              "   Shape_Length   Shape_Area  \n",
              "0   3110.360820  297836.0831  \n",
              "1   3519.469110  484945.1466  \n",
              "2   1697.091802  106705.9281  \n",
              "3   2922.609204  481828.4303  \n",
              "4   3731.971773  687684.7752  \n",
              "\n",
              "[5 rows x 117 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0d5bd4b-1485-4285-b373-2cb57bf64a9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OBJECTID</th>\n",
              "      <th>GEOID10</th>\n",
              "      <th>GEOID20</th>\n",
              "      <th>STATEFP</th>\n",
              "      <th>COUNTYFP</th>\n",
              "      <th>TRACTCE</th>\n",
              "      <th>BLKGRPCE</th>\n",
              "      <th>CSA</th>\n",
              "      <th>CSA_Name</th>\n",
              "      <th>CBSA</th>\n",
              "      <th>...</th>\n",
              "      <th>D5DRI</th>\n",
              "      <th>D5DE</th>\n",
              "      <th>D5DEI</th>\n",
              "      <th>D2A_Ranked</th>\n",
              "      <th>D2B_Ranked</th>\n",
              "      <th>D3B_Ranked</th>\n",
              "      <th>D4A_Ranked</th>\n",
              "      <th>NatWalkInd</th>\n",
              "      <th>Shape_Length</th>\n",
              "      <th>Shape_Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>48</td>\n",
              "      <td>113</td>\n",
              "      <td>7825</td>\n",
              "      <td>4</td>\n",
              "      <td>206.0</td>\n",
              "      <td>Dallas-Fort Worth, TX-OK</td>\n",
              "      <td>19100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.184697</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.137707</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3110.360820</td>\n",
              "      <td>297836.0831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>48</td>\n",
              "      <td>113</td>\n",
              "      <td>7825</td>\n",
              "      <td>2</td>\n",
              "      <td>206.0</td>\n",
              "      <td>Dallas-Fort Worth, TX-OK</td>\n",
              "      <td>19100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323221</td>\n",
              "      <td>0.000801</td>\n",
              "      <td>0.231868</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>10.833333</td>\n",
              "      <td>3519.469110</td>\n",
              "      <td>484945.1466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>48</td>\n",
              "      <td>113</td>\n",
              "      <td>7825</td>\n",
              "      <td>3</td>\n",
              "      <td>206.0</td>\n",
              "      <td>Dallas-Fort Worth, TX-OK</td>\n",
              "      <td>19100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.314628</td>\n",
              "      <td>0.000736</td>\n",
              "      <td>0.213146</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>17</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>1697.091802</td>\n",
              "      <td>106705.9281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>48</td>\n",
              "      <td>113</td>\n",
              "      <td>7824</td>\n",
              "      <td>1</td>\n",
              "      <td>206.0</td>\n",
              "      <td>Dallas-Fort Worth, TX-OK</td>\n",
              "      <td>19100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229821</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.205018</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>15.666667</td>\n",
              "      <td>2922.609204</td>\n",
              "      <td>481828.4303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>4.811300e+11</td>\n",
              "      <td>48</td>\n",
              "      <td>113</td>\n",
              "      <td>7824</td>\n",
              "      <td>2</td>\n",
              "      <td>206.0</td>\n",
              "      <td>Dallas-Fort Worth, TX-OK</td>\n",
              "      <td>19100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.164863</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>0.125296</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>10.166667</td>\n",
              "      <td>3731.971773</td>\n",
              "      <td>687684.7752</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 117 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0d5bd4b-1485-4285-b373-2cb57bf64a9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0d5bd4b-1485-4285-b373-2cb57bf64a9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0d5bd4b-1485-4285-b373-2cb57bf64a9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "walkability_df['CSA_Name'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlSG6jnf0B9s",
        "outputId": "2261e281-15fe-446d-ec59-3eed0569c55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Dallas-Fort Worth, TX-OK', 'Midland-Odessa, TX',\n",
              "       'Houston-The Woodlands, TX', 'Corpus Christi-Kingsville-Alice, TX',\n",
              "       nan, 'Lubbock-Plainview-Levelland, TX', 'McAllen-Edinburg, TX',\n",
              "       'Amarillo-Pampa-Borger, TX',\n",
              "       'San Antonio-New Braunfels-Pearsall, TX',\n",
              "       'Brownsville-Harlingen-Raymondville, TX',\n",
              "       'El Paso-Las Cruces, TX-NM', 'Tyler-Jacksonville, TX',\n",
              "       'Victoria-Port Lavaca, TX', 'Kerrville-Fredericksburg, TX',\n",
              "       'Virginia Beach-Norfolk, VA-NC',\n",
              "       'Washington-Baltimore-Arlington, DC-MD-VA-WV-PA',\n",
              "       'Harrisonburg-Staunton, VA',\n",
              "       'Johnson City-Kingsport-Bristol, TN-VA',\n",
              "       'Birmingham-Hoover-Talladega, AL',\n",
              "       'Columbus-Auburn-Opelika, GA-AL', 'Mobile-Daphne-Fairhope, AL',\n",
              "       'Dothan-Ozark, AL', 'Huntsville-Decatur, AL',\n",
              "       'Montgomery-Selma-Alexander City, AL', 'Scottsboro-Fort Payne, AL',\n",
              "       'Atlanta--Athens-Clarke County--Sandy Springs, GA-AL',\n",
              "       'Pensacola-Ferry Pass, FL-AL', 'Phoenix-Mesa, AZ',\n",
              "       'Tucson-Nogales, AZ', 'Hot Springs-Malvern, AR',\n",
              "       'Little Rock-North Little Rock, AR',\n",
              "       'Memphis-Forrest City, TN-MS-AR', 'Jonesboro-Paragould, AR',\n",
              "       'San Jose-San Francisco-Oakland, CA', 'Los Angeles-Long Beach, CA',\n",
              "       'Fresno-Madera-Hanford, CA', 'Sacramento-Roseville, CA',\n",
              "       'Redding-Red Bluff, CA', 'Denver-Aurora, CO',\n",
              "       'Pueblo-Cañon City, CO', 'Steamboat Springs-Craig, CO',\n",
              "       'Edwards-Glenwood Springs, CO', 'New York-Newark, NY-NJ-CT-PA',\n",
              "       'Hartford-East Hartford, CT',\n",
              "       'Boston-Worcester-Providence, MA-RI-NH-CT',\n",
              "       'Philadelphia-Reading-Camden, PA-NJ-DE-MD',\n",
              "       'Salisbury-Cambridge, MD-DE', 'Orlando-Lakeland-Deltona, FL',\n",
              "       'Cape Coral-Fort Myers-Naples, FL',\n",
              "       'Miami-Port St. Lucie-Fort Lauderdale, FL',\n",
              "       'North Port-Sarasota, FL', 'Gainesville-Lake City, FL',\n",
              "       'Jacksonville-St. Marys-Palatka, FL-GA',\n",
              "       'Chattanooga-Cleveland-Dalton, TN-GA',\n",
              "       'Macon-Bibb County--Warner Robins, GA',\n",
              "       'Savannah-Hinesville-Statesboro, GA',\n",
              "       'Idaho Falls-Rexburg-Blackfoot, ID',\n",
              "       'Boise City-Mountain Home-Ontario, ID-OR', 'Pullman-Moscow, WA-ID',\n",
              "       \"Spokane-Spokane Valley-Coeur d'Alene, WA-ID\",\n",
              "       'Dixon-Sterling, IL', 'Chicago-Naperville, IL-IN-WI',\n",
              "       'Rockford-Freeport-Rochelle, IL',\n",
              "       'St. Louis-St. Charles-Farmington, MO-IL',\n",
              "       'Davenport-Moline, IA-IL', 'Bloomington-Pontiac, IL',\n",
              "       'Springfield-Jacksonville-Lincoln, IL', 'Quincy-Hannibal, IL-MO',\n",
              "       'Cape Girardeau-Sikeston, MO-IL', 'Paducah-Mayfield, KY-IL',\n",
              "       'Burlington-Fort Madison-Keokuk, IA-IL-MO',\n",
              "       'Indianapolis-Carmel-Muncie, IN',\n",
              "       'Louisville/Jefferson County--Elizabethtown--Bardstown, KY-IN',\n",
              "       'Bloomington-Bedford, IN', 'Fort Wayne-Huntington-Auburn, IN',\n",
              "       'Richmond-Connersville, IN', 'South Bend-Elkhart-Mishawaka, IN-MI',\n",
              "       'Lafayette-West Lafayette-Frankfort, IN', 'Kokomo-Peru, IN',\n",
              "       'Cincinnati-Wilmington-Maysville, OH-KY-IN',\n",
              "       'Omaha-Council Bluffs-Fremont, NE-IA',\n",
              "       'Des Moines-Ames-West Des Moines, IA',\n",
              "       'Cedar Rapids-Iowa City, IA', 'Spencer-Spirit Lake, IA',\n",
              "       'Kansas City-Overland Park-Kansas City, MO-KS',\n",
              "       'Wichita-Winfield, KS',\n",
              "       'Lexington-Fayette--Richmond--Frankfort, KY',\n",
              "       'Bowling Green-Glasgow, KY',\n",
              "       'Charleston-Huntington-Ashland, WV-OH-KY',\n",
              "       'New Orleans-Metairie-Hammond, LA-MS',\n",
              "       'Lafayette-Opelousas-Morgan City, LA',\n",
              "       'DeRidder-Fort Polk South, LA', 'Lake Charles-Jennings, LA',\n",
              "       'Monroe-Ruston, LA', 'Shreveport-Bossier City-Minden, LA',\n",
              "       'Portland-Lewiston-South Portland, ME',\n",
              "       'Detroit-Warren-Ann Arbor, MI', 'Marinette-Iron Mountain, WI-MI',\n",
              "       'Saginaw-Midland-Bay City, MI',\n",
              "       'Kalamazoo-Battle Creek-Portage, MI',\n",
              "       'Grand Rapids-Kentwood-Muskegon, MI', 'Mount Pleasant-Alma, MI',\n",
              "       'Minneapolis-St. Paul, MN-WI', 'Mankato-New Ulm, MN',\n",
              "       'Rochester-Austin, MN', 'Fargo-Wahpeton, ND-MN',\n",
              "       'Jackson-Vicksburg-Brookhaven, MS', 'Tupelo-Corinth, MS',\n",
              "       'Columbus-West Point, MS', 'Hattiesburg-Laurel, MS',\n",
              "       'Cleveland-Indianola, MS', 'Joplin-Miami, MO-OK',\n",
              "       'Columbia-Moberly-Mexico, MO', 'Lincoln-Beatrice, NE',\n",
              "       'Reno-Carson City-Fernley, NV', 'Las Vegas-Henderson, NV',\n",
              "       'Albuquerque-Santa Fe-Las Vegas, NM', 'Clovis-Portales, NM',\n",
              "       'Elmira-Corning, NY', 'Buffalo-Cheektowaga-Olean, NY',\n",
              "       'Rochester-Batavia-Seneca Falls, NY', 'Albany-Schenectady, NY',\n",
              "       'Ithaca-Cortland, NY', 'Syracuse-Auburn, NY',\n",
              "       'Greensboro--Winston-Salem--High Point, NC',\n",
              "       'Charlotte-Concord, NC-SC', 'Fayetteville-Sanford-Lumberton, NC',\n",
              "       'New Bern-Morehead City, NC', 'Greenville-Kinston-Washington, NC',\n",
              "       'Rocky Mount-Wilson-Roanoke Rapids, NC',\n",
              "       'Asheville-Marion-Brevard, NC', 'Raleigh-Durham-Cary, NC',\n",
              "       'Myrtle Beach-Conway, SC-NC', 'Dayton-Springfield-Kettering, OH',\n",
              "       'Toledo-Findlay-Tiffin, OH', 'Cleveland-Akron-Canton, OH',\n",
              "       'Lima-Van Wert-Celina, OH', 'Youngstown-Warren, OH-PA',\n",
              "       'Columbus-Marion-Zanesville, OH', 'Mansfield-Ashland-Bucyrus, OH',\n",
              "       'Pittsburgh-New Castle-Weirton, PA-OH-WV',\n",
              "       'Parkersburg-Marietta-Vienna, WV-OH',\n",
              "       'Tulsa-Muskogee-Bartlesville, OK', 'Oklahoma City-Shawnee, OK',\n",
              "       'Portland-Vancouver-Salem, OR-WA', 'Medford-Grants Pass, OR',\n",
              "       'Bend-Prineville, OR', 'Harrisburg-York-Lebanon, PA',\n",
              "       'Altoona-Huntingdon, PA', 'Bloomsburg-Berwick-Sunbury, PA',\n",
              "       'State College-DuBois, PA', 'Erie-Meadville, PA',\n",
              "       'Johnstown-Somerset, PA', 'Williamsport-Lock Haven, PA',\n",
              "       'Greenville-Spartanburg-Anderson, SC',\n",
              "       'Columbia-Orangeburg-Newberry, SC', 'Rapid City-Spearfish, SD',\n",
              "       'Nashville-Davidson--Murfreesboro, TN',\n",
              "       'Knoxville-Morristown-Sevierville, TN', 'Jackson-Brownsville, TN',\n",
              "       'Martin-Union City, TN', 'Salt Lake City-Provo-Orem, UT',\n",
              "       'Burlington-South Burlington-Barre, VT', 'Seattle-Tacoma, WA',\n",
              "       'Moses Lake-Othello, WA', 'Kennewick-Richland-Walla Walla, WA',\n",
              "       'Morgantown-Fairmont, WV', 'Appleton-Oshkosh-Neenah, WI',\n",
              "       'Milwaukee-Racine-Waukesha, WI', 'Green Bay-Shawano, WI',\n",
              "       'Madison-Janesville-Beloit, WI', 'Eau Claire-Menomonie, WI',\n",
              "       'Wausau-Stevens Point-Wisconsin Rapids, WI',\n",
              "       'Ponce-Yauco-Coamo, PR', 'San Juan-Bayamón, PR',\n",
              "       'Mayagüez-San Germán, PR'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping Latent Variables"
      ],
      "metadata": {
        "id": "iecmzfmI1VoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_mapper = set(data1['RegionName'])\n",
        "print(data_mapper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I9LfLhh4F3P",
        "outputId": "99e77a71-1635-4b45-c537-2072a92efed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Waterloo, IA', 'Danville, VA', 'Morgan City, LA', 'DeRidder, LA', 'Wilmington, OH', 'Fairfield, IA', 'Midland, TX', 'Mount Vernon, IL', 'Carbondale, IL', 'Lawrenceburg, TN', 'Pinehurst, NC', 'Chattanooga, TN', 'Madison, IN', 'Hutchinson, MN', 'Farmington, NM', 'Moses Lake, WA', 'Kokomo, IN', 'Ann Arbor, MI', 'Fort Madison, IA', 'Thomasville, GA', 'McComb, MS', 'Ottawa, KS', 'Kirksville, MO', 'Decatur, AL', 'Ottawa, IL', 'Picayune, MS', 'McAllen, TX', 'Pittsburgh, PA', 'Kalamazoo, MI', 'Sheboygan, WI', 'New Orleans, LA', 'Harrisburg, PA', 'McMinnville, TN', 'Punta Gorda, FL', 'Denver, CO', 'Fredericksburg, TX', 'Twin Falls, ID', 'Cornelia, GA', 'New Philadelphia, OH', 'Kingsport, TN', 'Las Vegas, NM', 'San Antonio, TX', 'Lubbock, TX', 'Dallas, TX', 'Austin, TX', 'Lafayette, LA', 'Meridian, MS', 'Fernley, NV', 'Palestine, TX', 'West Plains, MO', 'Magnolia, AR', 'Raymondville, TX', 'Sedalia, MO', 'Elkins, WV', 'Glasgow, KY', 'Hutchinson, KS', 'Woodward, OK', 'Sterling, CO', 'Lebanon, NH', 'Dover, DE', 'Stevens Point, WI', 'Heber, UT', 'Brevard, NC', 'Odessa, TX', 'Racine, WI', 'Cookeville, TN', 'Sault Ste. Marie, MI', 'Bloomsburg, PA', 'Helena, AR', 'Alexandria, LA', 'Traverse City, MI', 'Mobile, AL', 'Seneca Falls, NY', 'Frankfort, KY', 'Albany, NY', 'Hot Springs, AR', 'Modesto, CA', 'Baraboo, WI', 'Crestview, FL', 'Oneonta, NY', 'Springfield, IL', 'Dalton, GA', 'Steamboat Springs, CO', 'Logan, UT', 'Spartanburg, SC', 'Owatonna, MN', 'Greensboro, NC', 'Panama City, FL', 'Washington, IN', 'Mount Vernon, OH', 'Walla Walla, WA', 'Cullowhee, NC', 'Naples, FL', 'New Bern, NC', 'Knoxville, TN', 'Stillwater, OK', 'Valdosta, GA', 'Sweetwater, TX', 'Lexington, NE', 'Fort Collins, CO', 'Coos Bay, OR', 'Laredo, TX', 'Huntington, IN', 'Yuba City, CA', 'Watertown, SD', 'Elkhart, IN', 'Warrensburg, MO', 'Butte, MT', 'Arkadelphia, AR', 'Fresno, CA', 'Boston, MA', 'Faribault, MN', 'Coshocton, OH', 'Rochester, NY', 'San Jose, CA', 'Flagstaff, AZ', 'Oil City, PA', 'Worcester, MA', 'Wheeling, WV', 'Grand Rapids, MI', 'Mansfield, OH', 'Edwards, CO', 'Troy, AL', 'Tupelo, MS', 'Tahlequah, OK', 'Sandpoint, ID', 'Sebring, FL', 'Rock Springs, WY', 'Mason City, IA', 'Yankton, SD', 'Anniston, AL', 'Mankato, MN', 'Albany, OR', 'Roseburg, OR', 'Decatur, IN', 'Allentown, PA', 'Boulder, CO', 'Riverside, CA', 'Huntington, WV', 'Crossville, TN', 'Barre, VT', 'Cedar City, UT', 'Bellefontaine, OH', 'Cullman, AL', 'Burlington, IA', 'Stockton, CA', 'Alpena, MI', 'Rockford, IL', 'Dayton, TN', 'Fitzgerald, GA', 'Clarksburg, WV', 'Eureka, CA', 'Jackson, MI', 'Greeley, CO', 'Jacksonville, IL', 'Davenport, IA', 'Bucyrus, OH', 'Tucson, AZ', 'Burlington, VT', 'St. Joseph, MO', 'Seneca, SC', 'Sandusky, OH', 'Shawano, WI', 'Marquette, MI', 'Huntingdon, PA', 'Talladega, AL', 'Austin, MN', 'Thomaston, GA', 'Detroit, MI', 'Clearlake, CA', 'Mexico, MO', 'Gillette, WY', 'La Crosse, WI', 'Bardstown, KY', 'Connersville, IN', 'Starkville, MS', 'Las Vegas, NV', 'Jackson, OH', 'Longview, TX', 'Newport, OR', 'Cedar Rapids, IA', 'Norfolk, NE', 'Uvalde, TX', 'Beaver Dam, WI', 'Des Moines, IA', 'Clovis, NM', 'Eagle Pass, TX', 'New York, NY', 'Helena, MT', 'Aberdeen, SD', 'Salinas, CA', 'Fond du Lac, WI', 'Plainview, TX', 'Lynchburg, VA', 'Springfield, OH', 'Murray, KY', 'Michigan City, IN', 'Bay City, TX', 'Fort Leonard Wood, MO', 'Sturgis, MI', 'Dumas, TX', 'Salt Lake City, UT', 'Montgomery, AL', 'Columbus, GA', 'Madera, CA', 'Vidalia, GA', 'Watertown, NY', 'Meadville, PA', 'Daphne, AL', 'Lock Haven, PA', 'Trenton, NJ', 'East Stroudsburg, PA', 'Carson City, NV', 'Sheridan, WY', 'Corsicana, TX', 'Mount Pleasant, TX', 'Burley, ID', 'Selinsgrove, PA', 'Nashville, TN', 'Corning, NY', 'Elmira, NY', 'Colorado Springs, CO', 'Orlando, FL', 'Sikeston, MO', 'Worthington, MN', 'Indianapolis, IN', 'Jacksonville, FL', 'Coffeyville, KS', 'Taylorville, IL', 'Cincinnati, OH', 'Milledgeville, GA', 'Pottsville, PA', 'Lafayette, IN', 'Marinette, WI', 'State College, PA', 'Ca-¦on City, CO', 'Auburn, IN', 'Palatka, FL', 'Klamath Falls, OR', 'Espa-¦ola, NM', 'Levelland, TX', 'Grand Forks, ND', 'Pierre, SD', 'Gainesville, GA', 'Pensacola, FL', 'Paragould, AR', 'Corpus Christi, TX', 'Charlottesville, VA', 'Bennettsville, SC', 'Hilton Head Island, SC', 'Garden City, KS', 'Statesboro, GA', 'Jackson, WY', 'Martin, TN', 'Grand Junction, CO', 'Terre Haute, IN', 'Big Spring, TX', 'Riverton, WY', 'Montrose, CO', 'Spearfish, SD', 'Sherman, TX', 'Jacksonville, NC', 'Amsterdam, NY', 'Huntsville, AL', 'Hastings, NE', 'Bradford, PA', 'Somerset, PA', 'Urban Honolulu, HI', 'Ludington, MI', 'Greenville, SC', 'Lake Charles, LA', 'Hanford, CA', 'Pine Bluff, AR', 'New Ulm, MN', 'Fort Polk South, LA', 'Boise City, ID', 'Lexington, KY', 'Tifton, GA', 'Brownsville, TX', 'Ogden, UT', 'Ukiah, CA', 'Syracuse, NY', 'Hagerstown, MD', 'Hilo, HI', 'Washington, NC', 'Bogalusa, LA', 'Cambridge, OH', 'Fort Wayne, IN', 'Mount Vernon, WA', 'Medford, OR', 'Greenville, NC', 'Waycross, GA', 'Gadsden, AL', 'Springfield, MA', 'Norwich, CT', 'Dothan, AL', 'Rio Grande City, TX', 'Van Wert, OH', 'Milwaukee, WI', 'Macomb, IL', 'Lewisburg, TN', 'Russellville, AR', 'Lincoln, IL', 'Poplar Bluff, MO', 'Sacramento, CA', 'Amarillo, TX', 'Madisonville, KY', 'Red Wing, MN', 'Great Bend, KS', 'Hays, KS', 'Hinesville, GA', 'Winona, MN', 'Durham, NC', 'Manitowoc, WI', 'Bedford, IN', 'Safford, AZ', 'Richmond, VA', 'Malvern, AR', 'Lamesa, TX', 'Sterling, IL', 'McPherson, KS', 'Danville, IL', 'Gettysburg, PA', 'Oxford, MS', 'Morgantown, WV', 'Flint, MI', 'Ketchikan, AK', 'El Paso, TX', 'Augusta, GA', 'Pampa, TX', 'Gardnerville Ranchos, NV', 'Liberal, KS', 'Alamogordo, NM', 'Pocatello, ID', 'Merced, CA', 'Natchitoches, LA', 'Peru, IN', 'Seymour, IN', 'Georgetown, SC', 'Brookings, SD', 'Pecos, TX', 'Cape Girardeau, MO', 'Tallahassee, FL', 'Brownwood, TX', 'Cheyenne, WY', 'Wapakoneta, OH', 'Keene, NH', 'Shelton, WA', 'Marion, NC', 'Utica, NY', 'Beatrice, NE', 'Martinsville, VA', 'Big Stone Gap, VA', 'Olean, NY', 'Wilmington, NC', 'Fergus Falls, MN', 'Huntsville, TX', 'Lima, OH', 'Winnemucca, NV', 'Arcadia, FL', 'Gaffney, SC', 'Killeen, TX', 'Laramie, WY', 'Angola, IN', 'Fremont, NE', 'Fremont, OH', 'Columbus, IN', 'Portsmouth, OH', 'Durant, OK', 'Santa Rosa, CA', 'Bremerton, WA', 'Hammond, LA', 'Owensboro, KY', 'Yakima, WA', 'Florence, SC', 'Dayton, OH', 'Abilene, TX', 'Stephenville, TX', 'Duluth, MN', 'Kahului, HI', 'Hood River, OR', 'Gloversville, NY', 'Visalia, CA', 'Muncie, IN', 'Portland, ME', 'Somerset, KY', 'Jasper, IN', 'Mount Sterling, KY', 'Tampa, FL', 'Alexandria, MN', 'Sebastian, FL', 'Baton Rouge, LA', 'Othello, WA', 'Seattle, WA', 'Blacksburg, VA', 'Dixon, IL', 'Willmar, MN', 'Enid, OK', 'Sulphur Springs, TX', 'Kill Devil Hills, NC', 'Philadelphia, PA', 'Columbia, MO', 'Lewiston, ME', 'Dodge City, KS', 'Toledo, OH', 'Minot, ND', 'Janesville, WI', 'Bluefield, WV', 'Marshalltown, IA', 'Bloomington, IN', 'Fallon, NV', 'Lawton, OK', 'Henderson, NC', 'Tulsa, OK', 'Altus, OK', 'Salem, OR', 'Duncan, OK', 'Gainesville, TX', 'Fayetteville, NC', 'Las Cruces, NM', 'Ruston, LA', 'Monroe, MI', 'Athens, OH', 'Ocean City, NJ', 'Cleveland, TN', 'Lawrence, KS', 'Lake Havasu City, AZ', 'Albert Lea, MN', 'Homosassa Springs, FL', 'Guymon, OK', 'Batesville, AR', 'Burlington, NC', 'Williamsport, PA', 'Clewiston, FL', 'Ames, IA', 'Oskaloosa, IA', 'Jamestown, ND', 'Searcy, AR', 'Warner Robins, GA', 'Defiance, OH', 'Battle Creek, MI', 'Wabash, IN', 'Centralia, WA', 'Bridgeport, CT', 'Erie, PA', 'Hudson, NY', 'Holland, MI', 'Providence, RI', 'Fayetteville, AR', 'Forest City, NC', 'Okeechobee, FL', 'Columbia, SC', 'Lebanon, PA', 'Port Angeles, WA', 'Chicago, IL', 'Wichita, KS', 'California, MD', 'Andrews, TX', 'Wichita Falls, TX', 'Oshkosh, WI', 'Del Rio, TX', 'Peoria, IL', 'Logansport, IN', 'Show Low, AZ', 'Warren, PA', 'Bainbridge, GA', 'Summerville, GA', 'Urbana, OH', 'Wooster, OH', 'Asheville, NC', 'Lancaster, PA', 'Berlin, NH', 'Miami, FL', 'Farmington, MO', 'Ithaca, NY', 'Salina, KS', 'Dyersburg, TN', 'Cape Coral, FL', 'Warsaw, IN', 'Concord, NH', 'Ozark, AL', 'Sidney, OH', 'Indiana, PA', 'Kennewick, WA', 'Vicksburg, MS', 'Cadillac, MI', 'Evansville, IN', 'Rutland, VT', 'Deltona, FL', 'Jackson, MS', 'Longview, WA', 'North Platte, NE', 'Vernon, TX', 'Point Pleasant, WV', 'Kinston, NC', 'Barnstable Town, MA', 'Easton, MD', 'Kalispell, MT', 'Ashtabula, OH', 'Charleston, WV', 'Juneau, AK', 'Winchester, VA', 'Pahrump, NV', 'Cordele, GA', 'Plattsburgh, NY', 'Snyder, TX', 'Fairbanks, AK', 'Bemidji, MN', 'The Villages, FL', 'New Castle, IN', 'Pittsburg, KS', 'Laconia, NH', 'Crawfordsville, IN', 'Nacogdoches, TX', 'Ardmore, OK', 'Hillsdale, MI', 'Auburn, NY', 'Union City, TN', 'Billings, MT', 'Wausau, WI', 'Richmond, KY', 'Chillicothe, OH', 'Bennington, VT', 'Olympia, WA', 'Albuquerque, NM', 'Hattiesburg, MS', 'Muscatine, IA', 'Great Falls, MT', 'Scranton, PA', 'Aberdeen, WA', 'Rochester, MN', 'Wisconsin Rapids, WI', 'Durango, CO', 'Evanston, WY', 'Gallup, NM', 'North Wilkesboro, NC', 'Lake City, FL', 'Boone, NC', 'Louisville, KY', 'Portland, OR', 'Cleveland, OH', 'Grand Island, NE', 'Richmond, IN', 'Dublin, GA', 'Dickinson, ND', 'Wenatchee, WA', 'Columbus, OH', 'Lebanon, MO', 'Vineyard Haven, MA', 'Greenwood, SC', 'Zanesville, OH', 'Morristown, TN', 'Niles, MI', 'Shreveport, LA', 'Johnstown, PA', 'Elizabethtown, KY', 'Craig, CO', 'Reading, PA', 'Omaha, NE', 'Napa, CA', 'Muskogee, OK', 'Hailey, ID', 'Salem, OH', 'Branson, MO', 'Winston, NC', 'Topeka, KS', 'Pullman, WA', 'Cortland, NY', 'Blytheville, AR', 'Beckley, WV', 'Newberry, SC', 'St. Louis, MO', 'Kankakee, IL', 'Port Lavaca, TX', 'Victoria, TX', 'Florence, AL', 'Marshall, MN', 'Spokane, WA', 'Galesburg, IL', 'Tiffin, OH', 'Roanoke, VA', 'Tyler, TX', 'Sayre, PA', 'Savannah, GA', 'London, KY', 'Fargo, ND', 'Americus, GA', 'San Francisco, CA', 'Idaho Falls, ID', 'Celina, OH', 'Cedartown, GA', 'Minneapolis, MN', 'York, PA', 'Brookhaven, MS', 'Hannibal, MO', 'Sonora, CA', 'Platteville, WI', 'Dubuque, IA', 'Albertville, AL', 'Iron Mountain, MI', 'Wauchula, FL', 'Staunton, VA', 'Effingham, IL', 'Mount Gay, WV', 'Maryville, MO', 'Oxnard, CA', 'Houma, LA', 'Kingston, NY', 'Rome, GA', 'Ada, OK', 'San Diego, CA', 'Roanoke Rapids, NC', 'Anchorage, AK', 'Rocky Mount, NC', 'Raleigh, NC', 'Escanaba, MI', 'Borger, TX', 'La Grande, OR', 'Scottsbluff, NE', 'Frankfort, IN', 'Manchester, NH', 'Canton, OH', 'Coldwater, MI', 'Brookings, OR', 'Appleton, WI', 'Whitewater, WI', 'Bay City, MI', 'Plymouth, IN', 'Fort Smith, AR', 'Lewistown, PA', 'Laurinburg, NC', 'Greensburg, IN', 'Sevierville, TN', 'Beeville, TX', 'Vineland, NJ', 'Manhattan, KS', 'Ponca City, OK', 'Roswell, NM', 'South Bend, IN', 'Greenwood, MS', 'Ogdensburg, NY', 'Grants Pass, OR', 'Muskegon, MI', 'Oak Harbor, WA', 'Brunswick, GA', 'Orangeburg, SC', 'Green Bay, WI', 'Redding, CA', 'Clarksville, TN', 'Los Angeles, CA', 'Akron, OH', 'Brainerd, MN', 'Bowling Green, KY', 'Charlotte, NC', 'Findlay, OH', 'Eugene, OR', 'Albany, GA', 'Oklahoma City, OK', 'San Luis Obispo, CA', 'Binghamton, NY', 'Houghton, MI', 'Marietta, OH', 'Opelousas, LA', 'Johnson City, TN', 'Bozeman, MT', 'Atchison, KS', 'Altoona, PA', 'Reno, NV', 'Torrington, CT', 'Chambersburg, PA', 'Cumberland, MD', 'Crescent City, CA', 'Deming, NM', 'Jamestown, NY', 'Mount Pleasant, MI', 'Quincy, IL', 'Selma, AL', 'Santa Cruz, CA', 'Athens, TN', 'Kerrville, TX', 'Sanford, NC', 'Paris, TN', 'The Dalles, OR', 'Tuscaloosa, AL', 'Santa Maria, CA', 'Mountain Home, ID', 'Atlantic City, NJ', 'Kansas City, MO', 'Mount Airy, NC', 'Vernal, UT', 'Breckenridge, CO', 'Ashland, OH', 'Calhoun, GA', 'Vermillion, SD', 'Jackson, TN', 'Jefferson, GA', 'LaGrange, GA', 'Ottumwa, IA', 'Prineville, OR', 'Waco, TX', 'Norwalk, OH', 'Moultrie, GA', 'Adrian, MI', 'Lumberton, NC', 'Monroe, LA', 'Camden, AR', 'Shawnee, OK', 'Harrisonburg, VA', 'Memphis, TN', 'St. George, UT', 'Jefferson City, MO', 'Birmingham, AL', 'Palm Bay, FL', 'Lincoln, NE', 'Sierra Vista, AZ', 'Hereford, TX', 'Kapaa, HI', 'Middlesborough, KY', 'Rexburg, ID', 'Nogales, AZ', 'Emporia, KS', 'Forrest City, AR', 'Rochelle, IL', 'Ellensburg, WA', 'Springfield, MO', 'Rolla, MO', 'Youngstown, OH', 'Ontario, OR', 'Truckee, CA', 'Toccoa, GA', 'Weatherford, OK', 'Virginia Beach, VA', 'El Campo, TX', 'Sioux City, IA', \"Coeur d'Alene, ID\", 'Washington Court House, OH', 'New Haven, CT', 'Kennett, MO', 'Chico, CA', 'Bakersfield, CA', 'Glens Falls, NY', 'Natchez, MS', 'Miami, OK', 'Malone, NY', 'Wahpeton, ND', 'Bend, OR', 'Indianola, MS', 'Rockingham, NC', 'New Castle, PA', 'El Dorado, AR', 'Little Rock, AR', 'Hobbs, NM', 'Alice, TX', 'Douglas, GA', 'Missoula, MT', 'Weirton, WV', 'Key West, FL', 'Batavia, NY', 'St. Cloud, MN', 'Watertown, WI', 'United States', 'Bismarck, ND', 'Salisbury, MD', 'Sioux Falls, SD', 'Lewiston, ID', 'St. Marys, GA', 'Corvallis, OR', 'Glenwood Springs, CO', 'Spirit Lake, IA', 'Columbus, MS', 'North Port, FL', 'Williston, ND', 'Baltimore, MD', 'Macon, GA', 'Lakeland, FL', 'Ocala, FL', 'Zapata, TX', 'Payson, AZ', 'Alma, MI', 'Hermiston, OR', 'Cambridge, MD', 'Paris, TX', 'Grenada, MS', 'Mayfield, KY', 'Menomonie, WI', 'Prescott Valley, AZ', 'Augusta, ME', 'Taos, NM', 'Elk City, OK', 'Washington, DC', 'Bangor, ME', 'Mineral Wells, TX', 'Bartlesville, OK', 'San Angelo, TX', 'Elko, NV', 'Spencer, IA', 'Los Alamos, NM', 'Fairmont, WV', 'Paducah, KY', 'Lewisburg, PA', 'Champaign, IL', 'DuBois, PA', 'McAlester, OK', 'Elizabeth City, NC', 'Shelbyville, TN', 'Midland, MI', 'Jacksonville, TX', 'Blackfoot, ID', 'Maysville, KY', 'Mitchell, SD', 'Casper, WY', 'Freeport, IL', 'Winfield, KS', 'Danville, KY', 'Provo, UT', 'Pittsfield, MA', 'Goldsboro, NC', 'Greeneville, TN', 'Brenham, TX', 'Enterprise, AL', 'Houston, TX', 'Kearney, NE', 'Gainesville, FL', 'Susanville, CA', 'Portales, NM', 'Saginaw, MI', 'Athens, TX', 'Marion, OH', 'Charleston, SC', 'Auburn, AL', 'Moberly, MO', 'El Centro, CA', 'Pueblo, CO', 'Campbellsville, KY', 'Hartford, CT', 'Marshall, MO', 'Big Rapids, MI', 'Lansing, MI', 'Buffalo, NY', 'Jonesboro, AR', 'Scottsboro, AL', 'Clinton, IA', 'Harrison, AR', 'Madison, WI', 'North Vernon, IN', 'Myrtle Beach, SC', 'Phoenix, AZ', 'Rapid City, SD', 'Charleston, IL', 'Greenville, OH', 'Bellingham, WA', 'Vincennes, IN', 'Kendallville, IN', 'Kingsville, TX', 'Mountain Home, AR', 'Parsons, KS', 'Newport, TN', 'Parkersburg, WV', 'Marion, IN', 'Eau Claire, WI', 'Red Bluff, CA', 'Decatur, IL', 'Morehead City, NC', 'Sumter, SC', 'Shelby, NC', 'Jesup, GA', 'Laurel, MS', 'Tullahoma, TN', 'Gulfport, MS', 'Corinth, MS', 'Joplin, MO', 'Columbus, NE', 'Lufkin, TX', 'Sunbury, PA', 'Yuma, AZ', 'Hickory, NC', 'Santa Fe, NM', 'Iowa City, IA', 'Bloomington, IL', 'Astoria, OR', 'Beaumont, TX', 'Atlanta, GA', 'Storm Lake, IA', 'Wilson, NC', 'Silver City, NM', 'Vallejo, CA', 'Athens, GA', 'College Station, TX', 'Texarkana, TX', 'Port St. Lucie, FL', 'Fort Morgan, CO', 'Moscow, ID', 'Pontiac, IL'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lv_mapper(column):\n",
        "  idx_mapper = dict(walkability_df.groupby(['CSA_Name'])[column].mean())\n",
        "  idx_data_mapper = {}\n",
        "\n",
        "  for d in data_mapper:\n",
        "    for i in idx_mapper:\n",
        "      if d.split(',')[0] in i:\n",
        "        idx_data_mapper[d] = idx_mapper[i]\n",
        "        break\n",
        "  return idx_data_mapper"
      ],
      "metadata": {
        "id": "ZpcPjQbi_0XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = data1.fillna(method=\"ffill\")"
      ],
      "metadata": {
        "id": "kJR536eH73x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nwi_mapper = lv_mapper('NatWalkInd')\n",
        "met_mapper = lv_mapper('D2B_E8MIXA')\n",
        "data1['NatWalkInd'] = data1['RegionName'].map(nwi_mapper)\n",
        "data1['D2B_E8MIXA'] = data1['RegionName'].map(met_mapper)\n",
        "data1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "cTgkSFV57Ext",
        "outputId": "19f0ba6d-ff54-4c0a-daf7-b17d49630bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RegionID  SizeRank       RegionName RegionType StateName  2000-01-31  \\\n",
              "0    102001         0    United States    country       NaN    127845.0   \n",
              "1    394913         1     New York, NY        msa        NY    222885.0   \n",
              "2    753899         2  Los Angeles, CA        msa        CA    230273.0   \n",
              "3    394463         3      Chicago, IL        msa        IL    167528.0   \n",
              "4    394514         4       Dallas, TX        msa        TX    128766.0   \n",
              "\n",
              "   2000-02-29  2000-03-31  2000-04-30  2000-05-31  ...  2022-05-31  \\\n",
              "0    128190.0    128554.0    129295.0    130042.0  ...    348315.0   \n",
              "1    224217.0    225415.0    227774.0    229970.0  ...    601691.0   \n",
              "2    231075.0    232303.0    234638.0    237142.0  ...    940540.0   \n",
              "3    167923.0    168434.0    169458.0    170543.0  ...    302975.0   \n",
              "4    128869.0    128955.0    129164.0    129383.0  ...    381724.0   \n",
              "\n",
              "   2022-06-30  2022-07-31  2022-08-31  2022-09-30  2022-10-31  2022-11-30  \\\n",
              "0    352484.0    354884.0    355924.0    356279.0    356785.0    357296.0   \n",
              "1    607653.0    611940.0    614208.0    615185.0    615662.0    616681.0   \n",
              "2    941881.0    938738.0    924623.0    914991.0    905397.0    900776.0   \n",
              "3    305916.0    307737.0    308055.0    308352.0    308969.0    309456.0   \n",
              "4    389176.0    391350.0    390417.0    388728.0    388858.0    388704.0   \n",
              "\n",
              "   2022-12-31  NatWalkInd  D2B_E8MIXA  \n",
              "0    357319.0         NaN         NaN  \n",
              "1    617849.0   12.158994    0.549763  \n",
              "2    897894.0   12.890648    0.562545  \n",
              "3    308959.0   11.707006    0.500333  \n",
              "4    386853.0    9.901212    0.507137  \n",
              "\n",
              "[5 rows x 283 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3a7ee55-b46b-4b3a-9421-867575b272c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RegionID</th>\n",
              "      <th>SizeRank</th>\n",
              "      <th>RegionName</th>\n",
              "      <th>RegionType</th>\n",
              "      <th>StateName</th>\n",
              "      <th>2000-01-31</th>\n",
              "      <th>2000-02-29</th>\n",
              "      <th>2000-03-31</th>\n",
              "      <th>2000-04-30</th>\n",
              "      <th>2000-05-31</th>\n",
              "      <th>...</th>\n",
              "      <th>2022-05-31</th>\n",
              "      <th>2022-06-30</th>\n",
              "      <th>2022-07-31</th>\n",
              "      <th>2022-08-31</th>\n",
              "      <th>2022-09-30</th>\n",
              "      <th>2022-10-31</th>\n",
              "      <th>2022-11-30</th>\n",
              "      <th>2022-12-31</th>\n",
              "      <th>NatWalkInd</th>\n",
              "      <th>D2B_E8MIXA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102001</td>\n",
              "      <td>0</td>\n",
              "      <td>United States</td>\n",
              "      <td>country</td>\n",
              "      <td>NaN</td>\n",
              "      <td>127845.0</td>\n",
              "      <td>128190.0</td>\n",
              "      <td>128554.0</td>\n",
              "      <td>129295.0</td>\n",
              "      <td>130042.0</td>\n",
              "      <td>...</td>\n",
              "      <td>348315.0</td>\n",
              "      <td>352484.0</td>\n",
              "      <td>354884.0</td>\n",
              "      <td>355924.0</td>\n",
              "      <td>356279.0</td>\n",
              "      <td>356785.0</td>\n",
              "      <td>357296.0</td>\n",
              "      <td>357319.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>394913</td>\n",
              "      <td>1</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>msa</td>\n",
              "      <td>NY</td>\n",
              "      <td>222885.0</td>\n",
              "      <td>224217.0</td>\n",
              "      <td>225415.0</td>\n",
              "      <td>227774.0</td>\n",
              "      <td>229970.0</td>\n",
              "      <td>...</td>\n",
              "      <td>601691.0</td>\n",
              "      <td>607653.0</td>\n",
              "      <td>611940.0</td>\n",
              "      <td>614208.0</td>\n",
              "      <td>615185.0</td>\n",
              "      <td>615662.0</td>\n",
              "      <td>616681.0</td>\n",
              "      <td>617849.0</td>\n",
              "      <td>12.158994</td>\n",
              "      <td>0.549763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>753899</td>\n",
              "      <td>2</td>\n",
              "      <td>Los Angeles, CA</td>\n",
              "      <td>msa</td>\n",
              "      <td>CA</td>\n",
              "      <td>230273.0</td>\n",
              "      <td>231075.0</td>\n",
              "      <td>232303.0</td>\n",
              "      <td>234638.0</td>\n",
              "      <td>237142.0</td>\n",
              "      <td>...</td>\n",
              "      <td>940540.0</td>\n",
              "      <td>941881.0</td>\n",
              "      <td>938738.0</td>\n",
              "      <td>924623.0</td>\n",
              "      <td>914991.0</td>\n",
              "      <td>905397.0</td>\n",
              "      <td>900776.0</td>\n",
              "      <td>897894.0</td>\n",
              "      <td>12.890648</td>\n",
              "      <td>0.562545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>394463</td>\n",
              "      <td>3</td>\n",
              "      <td>Chicago, IL</td>\n",
              "      <td>msa</td>\n",
              "      <td>IL</td>\n",
              "      <td>167528.0</td>\n",
              "      <td>167923.0</td>\n",
              "      <td>168434.0</td>\n",
              "      <td>169458.0</td>\n",
              "      <td>170543.0</td>\n",
              "      <td>...</td>\n",
              "      <td>302975.0</td>\n",
              "      <td>305916.0</td>\n",
              "      <td>307737.0</td>\n",
              "      <td>308055.0</td>\n",
              "      <td>308352.0</td>\n",
              "      <td>308969.0</td>\n",
              "      <td>309456.0</td>\n",
              "      <td>308959.0</td>\n",
              "      <td>11.707006</td>\n",
              "      <td>0.500333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>394514</td>\n",
              "      <td>4</td>\n",
              "      <td>Dallas, TX</td>\n",
              "      <td>msa</td>\n",
              "      <td>TX</td>\n",
              "      <td>128766.0</td>\n",
              "      <td>128869.0</td>\n",
              "      <td>128955.0</td>\n",
              "      <td>129164.0</td>\n",
              "      <td>129383.0</td>\n",
              "      <td>...</td>\n",
              "      <td>381724.0</td>\n",
              "      <td>389176.0</td>\n",
              "      <td>391350.0</td>\n",
              "      <td>390417.0</td>\n",
              "      <td>388728.0</td>\n",
              "      <td>388858.0</td>\n",
              "      <td>388704.0</td>\n",
              "      <td>386853.0</td>\n",
              "      <td>9.901212</td>\n",
              "      <td>0.507137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 283 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3a7ee55-b46b-4b3a-9421-867575b272c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3a7ee55-b46b-4b3a-9421-867575b272c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3a7ee55-b46b-4b3a-9421-867575b272c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "7mCG2wzK8H55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Catzt05q9Lad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_nlv = data1.drop(columns=['RegionID','RegionType','StateName', 'SizeRank'])\n",
        "train_data_nlv_x = train_data_nlv[['2000-12-31', '2001-12-31', '2002-12-31', '2003-12-31', '2004-12-31', '2005-12-31', '2006-12-31', '2007-12-31', '2008-12-31','2009-12-31','2010-12-31', '2011-12-31', '2012-12-31', '2013-12-31', '2014-12-31','2015-12-31', '2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31']]\n",
        "train_data_nlv_y= train_data_nlv['2022-12-31']"
      ],
      "metadata": {
        "id": "6oLRiXuNKinV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_nlv_x_train, train_data_nlv_x_test, train_data_nlv_y_train, train_data_nlv_y_test = train_test_split(train_data_nlv_x, train_data_nlv_y, test_size=0.25, random_state=12)"
      ],
      "metadata": {
        "id": "t5qbjulNK4tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "National Walking Index as Latent Variable 1"
      ],
      "metadata": {
        "id": "NlSasHXE-2oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_lv1 = data1.drop(columns=['RegionID','RegionType','StateName', 'SizeRank'])\n",
        "train_data_lv1_x = train_data_lv1[['2000-12-31', '2001-12-31', '2002-12-31', '2003-12-31', '2004-12-31', '2005-12-31', '2006-12-31', '2007-12-31', '2008-12-31','2009-12-31','2010-12-31', '2011-12-31', '2012-12-31', '2013-12-31', '2014-12-31','2015-12-31', '2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31', 'NatWalkInd']].fillna(train_data_lv1['NatWalkInd'].mean())\n",
        "train_data_lv1_y= train_data_lv1['2022-12-31'].fillna(method=\"ffill\")"
      ],
      "metadata": {
        "id": "Wmk9MQ0e8Hm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_lv1_x_train, train_data_lv1_x_test, train_data_lv1_y_train, train_data_lv1_y_test = train_test_split(train_data_lv1_x, train_data_lv1_y, test_size=0.25, random_state=12)"
      ],
      "metadata": {
        "id": "djYTpqzp9AOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mix of Employment Types as Latent Variable 2"
      ],
      "metadata": {
        "id": "OPRB9tEt-6tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_lv2 = data1.drop(columns=['RegionID','RegionType','StateName', 'SizeRank'])\n",
        "train_data_lv2_x = train_data_lv2[['2000-12-31', '2001-12-31', '2002-12-31', '2003-12-31', '2004-12-31', '2005-12-31', '2006-12-31', '2007-12-31', '2008-12-31','2009-12-31','2010-12-31', '2011-12-31', '2012-12-31', '2013-12-31', '2014-12-31','2015-12-31', '2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31', 'D2B_E8MIXA']].fillna(train_data_lv2['D2B_E8MIXA'].mean())\n",
        "train_data_lv2_y= train_data_lv2['2022-12-31'].fillna(method=\"ffill\")"
      ],
      "metadata": {
        "id": "1dMh-ooe-8iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_lv2_x_train, train_data_lv2_x_test, train_data_lv2_y_train, train_data_lv2_y_test = train_test_split(train_data_lv2_x, train_data_lv2_y, test_size=0.25, random_state=12)"
      ],
      "metadata": {
        "id": "Za4JmRAB-_-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mix of Employment Types + National Walking Index as Latent Variables"
      ],
      "metadata": {
        "id": "2JwRKVlS_Hai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_lv12_x = train_data_lv1_x\n",
        "train_data_lv12_x['D2B_E8MIXA'] = train_data_lv2_x['D2B_E8MIXA']\n",
        "train_data_lv12_y= train_data_lv2['2022-12-31'].fillna(method=\"ffill\")"
      ],
      "metadata": {
        "id": "bxVSunK3_GIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_lv12_x_train, train_data_lv12_x_test, train_data_lv12_y_train, train_data_lv12_y_test = train_test_split(train_data_lv12_x, train_data_lv12_y, test_size=0.25, random_state=12)"
      ],
      "metadata": {
        "id": "jk_EFoFy_Mlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Muller Loop"
      ],
      "metadata": {
        "id": "Sb-9V1UntLl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "QSsaYZfYTnPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import metrics\n",
        "names = [\n",
        "    \"Linear Regression\",\n",
        "    \"MLP Regressor\",\n",
        "    \"RandomForest Regressor\",\n",
        "    \"Gradient Boosting Regressor\",\n",
        "    \"KNeighbors Regressor\"\n",
        "         ]\n",
        "\n",
        "classifiers = [\n",
        "    LinearRegression(),\n",
        "    MLPRegressor(random_state=1, max_iter=500),\n",
        "    RandomForestRegressor(max_depth=4, random_state=1),\n",
        "    GradientBoostingRegressor(random_state=1),\n",
        "    KNeighborsRegressor(n_neighbors=2)\n",
        "    ]"
      ],
      "metadata": {
        "id": "NCl6KR9ltaIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Muller Loop Function"
      ],
      "metadata": {
        "id": "fdhMlE21Tr9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def muller_loop(x_train, x_test, y_train, y_test):\n",
        "  max_score = 0.0\n",
        "  max_class = ''\n",
        "  # iterate over classifiers\n",
        "  metrics_df = pd.DataFrame({\n",
        "      'Classifier': [],\n",
        "      'MSE' : [], \n",
        "      'MAE': [],\n",
        "      'RSquared': [],\n",
        "      'Test Accuracy': []\n",
        "      })\n",
        "  for name, clf in zip(names, classifiers):\n",
        "      clf.fit(x_train, y_train)\n",
        "      y_pred = clf.predict(x_test)\n",
        "      score = 100.0 * clf.score(x_test, y_test)\n",
        "      mean_absolute_error = np.round(metrics.mean_absolute_error(y_test, y_pred), 2)\n",
        "      mean_squared_error = np.round(metrics.mean_squared_error(y_test, y_pred), 2)\n",
        "      r_squared = np.round(metrics.r2_score(y_test, y_pred), 2)\n",
        "     \n",
        "      new_row = pd.DataFrame({\n",
        "      'Classifier': name,   \n",
        "      'MSE' : mean_absolute_error, \n",
        "      'MAE': mean_squared_error,\n",
        "      'RSquared': r_squared,\n",
        "      'Test Accuracy': score}, index=[0])\n",
        "      metrics_df = pd.concat([new_row,metrics_df.loc[:]]).reset_index(drop=True)\n",
        "\n",
        "      print('Classifier = %s, Score (test, accuracy) = %.2f,' %(name, score))\n",
        "      if score > max_score:\n",
        "          clf_best = clf\n",
        "          max_score = score\n",
        "          max_class = name\n",
        "\n",
        "  print('Best --> Classifier = %s, Score (test, accuracy) = %.2f' %(max_class, max_score))\n",
        "  return metrics_df"
      ],
      "metadata": {
        "id": "QsAOmgHztPce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "aW1I_vlMSxQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Latent Variables"
      ],
      "metadata": {
        "id": "wV6KihmpKa12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlv_metrics_df = muller_loop(train_data_nlv_x_train, train_data_nlv_x_test, train_data_nlv_y_train, train_data_nlv_y_test)\n",
        "nlv_metrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "DgMDBC06Kc--",
        "outputId": "fb80f1c3-b017-427f-852d-28a2452bc7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier = Linear Regression, Score (test, accuracy) = 95.24,\n",
            "Classifier = MLP Regressor, Score (test, accuracy) = 95.69,\n",
            "Classifier = RandomForest Regressor, Score (test, accuracy) = 94.72,\n",
            "Classifier = Gradient Boosting Regressor, Score (test, accuracy) = 95.83,\n",
            "Classifier = KNeighbors Regressor, Score (test, accuracy) = 93.26,\n",
            "Best --> Classifier = Gradient Boosting Regressor, Score (test, accuracy) = 95.83\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Classifier       MSE           MAE  RSquared  \\\n",
              "0         KNeighbors Regressor  26806.69  2.568879e+09      0.93   \n",
              "1  Gradient Boosting Regressor  16682.71  1.589813e+09      0.96   \n",
              "2       RandomForest Regressor  18723.87  2.012339e+09      0.95   \n",
              "3                MLP Regressor  16401.45  1.644024e+09      0.96   \n",
              "4            Linear Regression  17265.97  1.814788e+09      0.95   \n",
              "\n",
              "   Test Accuracy  \n",
              "0      93.264353  \n",
              "1      95.831482  \n",
              "2      94.723611  \n",
              "3      95.689341  \n",
              "4      95.241593  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ff0c15e-c20c-43b5-a713-669740d9c034\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RSquared</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighbors Regressor</td>\n",
              "      <td>26806.69</td>\n",
              "      <td>2.568879e+09</td>\n",
              "      <td>0.93</td>\n",
              "      <td>93.264353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>16682.71</td>\n",
              "      <td>1.589813e+09</td>\n",
              "      <td>0.96</td>\n",
              "      <td>95.831482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest Regressor</td>\n",
              "      <td>18723.87</td>\n",
              "      <td>2.012339e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>94.723611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MLP Regressor</td>\n",
              "      <td>16401.45</td>\n",
              "      <td>1.644024e+09</td>\n",
              "      <td>0.96</td>\n",
              "      <td>95.689341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>17265.97</td>\n",
              "      <td>1.814788e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>95.241593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ff0c15e-c20c-43b5-a713-669740d9c034')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ff0c15e-c20c-43b5-a713-669740d9c034 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ff0c15e-c20c-43b5-a713-669740d9c034');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Latent Variable 1: National Walking Index"
      ],
      "metadata": {
        "id": "nea-n4N4CrlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nwi_metrics_df = muller_loop(train_data_lv1_x_train, train_data_lv1_x_test, train_data_lv1_y_train, train_data_lv1_y_test)\n",
        "nwi_metrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Q3h0YDbv7DW4",
        "outputId": "af2fca08-63df-4ff4-da3d-59a5e31aa4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier = Linear Regression, Score (test, accuracy) = 95.25,\n",
            "Classifier = MLP Regressor, Score (test, accuracy) = 95.92,\n",
            "Classifier = RandomForest Regressor, Score (test, accuracy) = 94.74,\n",
            "Classifier = Gradient Boosting Regressor, Score (test, accuracy) = 95.58,\n",
            "Classifier = KNeighbors Regressor, Score (test, accuracy) = 93.26,\n",
            "Best --> Classifier = MLP Regressor, Score (test, accuracy) = 95.92\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Classifier       MSE           MAE  RSquared  \\\n",
              "0         KNeighbors Regressor  26806.69  2.568879e+09      0.93   \n",
              "1  Gradient Boosting Regressor  16936.68  1.686400e+09      0.96   \n",
              "2       RandomForest Regressor  18703.22  2.006466e+09      0.95   \n",
              "3                MLP Regressor  16325.12  1.557035e+09      0.96   \n",
              "4            Linear Regression  17123.37  1.813105e+09      0.95   \n",
              "\n",
              "   Test Accuracy  \n",
              "0      93.264353  \n",
              "1      95.578228  \n",
              "2      94.739011  \n",
              "3      95.917427  \n",
              "4      95.246007  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e273ae5-5959-46d0-a217-39f3b0ff97ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RSquared</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighbors Regressor</td>\n",
              "      <td>26806.69</td>\n",
              "      <td>2.568879e+09</td>\n",
              "      <td>0.93</td>\n",
              "      <td>93.264353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>16936.68</td>\n",
              "      <td>1.686400e+09</td>\n",
              "      <td>0.96</td>\n",
              "      <td>95.578228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest Regressor</td>\n",
              "      <td>18703.22</td>\n",
              "      <td>2.006466e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>94.739011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MLP Regressor</td>\n",
              "      <td>16325.12</td>\n",
              "      <td>1.557035e+09</td>\n",
              "      <td>0.96</td>\n",
              "      <td>95.917427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>17123.37</td>\n",
              "      <td>1.813105e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>95.246007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e273ae5-5959-46d0-a217-39f3b0ff97ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e273ae5-5959-46d0-a217-39f3b0ff97ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e273ae5-5959-46d0-a217-39f3b0ff97ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Latent Variable 2: Mix of Employment Types"
      ],
      "metadata": {
        "id": "N-x2la4ZCt_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "met_metrics_df = muller_loop(train_data_lv2_x_train, train_data_lv2_x_test, train_data_lv2_y_train, train_data_lv2_y_test)\n",
        "met_metrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "uDppNHb7CtKl",
        "outputId": "c6fe3e6f-df1d-412d-d3fa-ffca758d7ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier = Linear Regression, Score (test, accuracy) = 95.23,\n",
            "Classifier = MLP Regressor, Score (test, accuracy) = 95.94,\n",
            "Classifier = RandomForest Regressor, Score (test, accuracy) = 94.75,\n",
            "Classifier = Gradient Boosting Regressor, Score (test, accuracy) = 95.67,\n",
            "Classifier = KNeighbors Regressor, Score (test, accuracy) = 93.26,\n",
            "Best --> Classifier = MLP Regressor, Score (test, accuracy) = 95.94\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Classifier       MSE           MAE  RSquared  \\\n",
              "0         KNeighbors Regressor  26806.69  2.568879e+09      0.93   \n",
              "1  Gradient Boosting Regressor  17131.66  1.651867e+09      0.96   \n",
              "2       RandomForest Regressor  18684.79  2.000928e+09      0.95   \n",
              "3                MLP Regressor  16242.21  1.549574e+09      0.96   \n",
              "4            Linear Regression  17357.44  1.819188e+09      0.95   \n",
              "\n",
              "   Test Accuracy  \n",
              "0      93.264353  \n",
              "1      95.668775  \n",
              "2      94.753531  \n",
              "3      95.936990  \n",
              "4      95.230058  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f24e4e89-3792-4510-bac5-e35b94285367\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RSquared</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighbors Regressor</td>\n",
              "      <td>26806.69</td>\n",
              "      <td>2.568879e+09</td>\n",
              "      <td>0.93</td>\n",
              "      <td>93.264353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>17131.66</td>\n",
              "      <td>1.651867e+09</td>\n",
              "      <td>0.96</td>\n",
              "      <td>95.668775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest Regressor</td>\n",
              "      <td>18684.79</td>\n",
              "      <td>2.000928e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>94.753531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MLP Regressor</td>\n",
              "      <td>16242.21</td>\n",
              "      <td>1.549574e+09</td>\n",
              "      <td>0.96</td>\n",
              "      <td>95.936990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>17357.44</td>\n",
              "      <td>1.819188e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>95.230058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f24e4e89-3792-4510-bac5-e35b94285367')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f24e4e89-3792-4510-bac5-e35b94285367 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f24e4e89-3792-4510-bac5-e35b94285367');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Latent Variables 1&2: Mix of Employment Types + National Walking Index"
      ],
      "metadata": {
        "id": "FnP4JgyBCzu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "met_nwi_metrics_df = muller_loop(train_data_lv12_x_train, train_data_lv12_x_test, train_data_lv12_y_train, train_data_lv12_y_test )\n",
        "met_nwi_metrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Sbi6pgwnC2HV",
        "outputId": "ad8b1e54-e868-4603-e376-76f5c045adbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier = Linear Regression, Score (test, accuracy) = 95.24,\n",
            "Classifier = MLP Regressor, Score (test, accuracy) = 95.33,\n",
            "Classifier = RandomForest Regressor, Score (test, accuracy) = 94.83,\n",
            "Classifier = Gradient Boosting Regressor, Score (test, accuracy) = 95.71,\n",
            "Classifier = KNeighbors Regressor, Score (test, accuracy) = 93.26,\n",
            "Best --> Classifier = Gradient Boosting Regressor, Score (test, accuracy) = 95.71\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Classifier       MSE           MAE  RSquared  \\\n",
              "0         KNeighbors Regressor  26806.69  2.568879e+09      0.93   \n",
              "1  Gradient Boosting Regressor  16949.14  1.637567e+09      0.96   \n",
              "2       RandomForest Regressor  18642.77  1.972650e+09      0.95   \n",
              "3                MLP Regressor  18511.23  1.781657e+09      0.95   \n",
              "4            Linear Regression  17179.29  1.816498e+09      0.95   \n",
              "\n",
              "   Test Accuracy  \n",
              "0      93.264353  \n",
              "1      95.706271  \n",
              "2      94.827676  \n",
              "3      95.328463  \n",
              "4      95.237109  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63f07365-ebd0-412b-81db-69fedec2bba4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RSquared</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighbors Regressor</td>\n",
              "      <td>26806.69</td>\n",
              "      <td>2.568879e+09</td>\n",
              "      <td>0.93</td>\n",
              "      <td>93.264353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>16949.14</td>\n",
              "      <td>1.637567e+09</td>\n",
              "      <td>0.96</td>\n",
              "      <td>95.706271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest Regressor</td>\n",
              "      <td>18642.77</td>\n",
              "      <td>1.972650e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>94.827676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MLP Regressor</td>\n",
              "      <td>18511.23</td>\n",
              "      <td>1.781657e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>95.328463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>17179.29</td>\n",
              "      <td>1.816498e+09</td>\n",
              "      <td>0.95</td>\n",
              "      <td>95.237109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f07365-ebd0-412b-81db-69fedec2bba4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63f07365-ebd0-412b-81db-69fedec2bba4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63f07365-ebd0-412b-81db-69fedec2bba4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Layer Perceptron using Keras"
      ],
      "metadata": {
        "id": "9RJ0V0GcpPXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing essential libraries for Neural Network"
      ],
      "metadata": {
        "id": "9iHtFyFvTBYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "plt.rcParams.update({'figure.figsize': (12.0, 8.0)})\n",
        "plt.rcParams.update({'font.size': 14})"
      ],
      "metadata": {
        "id": "qAcLOUjSqMYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building and Compilation"
      ],
      "metadata": {
        "id": "oB9n3Ao-TJmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data_lv12_x, train_data_lv12_y, test_size=0.25, random_state=12)\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(24,))),\n",
        "model.add(Dense(12, input_shape=(24,), activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, epochs=1000, batch_size=10)\n",
        "\n",
        "# evaluate the keras model\n",
        "_ , accuracy = model.evaluate(X_train, y_train)\n",
        "\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "# make class predictions with the model\n",
        "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# for i in X_train.columns:\n",
        "# \tprint('%s => %d (expected %d)' % (X_train[i].tolist(), predictions[i], y_test[i]))"
      ],
      "metadata": {
        "id": "FwuIn-qEqRbG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43fe4fe6-084d-4ced-e158-2f600e9e8d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "67/67 [==============================] - 1s 4ms/step - loss: 100946722816.0000 - accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946657280.0000 - accuracy: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946722816.0000 - accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946657280.0000 - accuracy: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946657280.0000 - accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946722816.0000 - accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 466/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 477/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 478/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 479/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 480/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 481/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 483/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 517/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 519/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 577/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 579/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 580/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 581/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 590/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 591/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 593/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 594/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 601/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946657280.0000 - accuracy: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 642/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 701/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 719/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946722816.0000 - accuracy: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 742/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 746/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 749/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 750/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 757/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 762/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946665472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946731008.0000 - accuracy: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946714624.0000 - accuracy: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946673664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946698240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946690048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 100946706432.0000 - accuracy: 0.0000e+00\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 100946681856.0000 - accuracy: 0.0000e+00\n",
            "Accuracy: 0.00\n",
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-3d86d1e3ab10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s => %d (expected %d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    }
  ]
}